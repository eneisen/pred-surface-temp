{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../final_data/label_keys_ts.pkl', 'rb') as fp:\n",
    "    label_keys = pickle.load(fp)\n",
    "with open ('../final_data/feature_keys_ts.pkl', 'rb') as fp:\n",
    "    feature_keys = pickle.load(fp)    \n",
    "\n",
    "train_x = load('../final_data/train_x_norm.npy')\n",
    "train_y = load('../final_data/train_y_norm.npy')\n",
    "valid_x = load('../final_data/valid_x_norm.npy')\n",
    "valid_y = load('../final_data/valid_y_norm.npy')\n",
    "test_x = load('../final_data/test_x_norm.npy')\n",
    "test_y = load('../final_data/test_y_norm.npy')\n",
    "all_train_x = load('../final_data/all_train_x_norm.npy')\n",
    "all_train_y = load('../final_data/all_train_y_norm.npy')\n",
    "\n",
    "scaler_x = joblib.load(\"../final_data/scaler_x.save\") \n",
    "scaler_y = joblib.load(\"../final_data/scaler_y.save\") \n",
    "\n",
    "scaler_train_x = joblib.load(\"../final_data/scaler_train_x.save\") \n",
    "scaler_train_y = joblib.load(\"../final_data/scaler_train_y.save\")\n",
    "\n",
    "train_unsc = pd.read_pickle(\"../final_data/train_unsc.pkl\")\n",
    "valid_unsc = pd.read_pickle(\"../final_data/valid_unsc.pkl\")\n",
    "test_unsc = pd.read_pickle(\"../final_data/test_unsc.pkl\")\n",
    "all_train_unsc = pd.read_pickle(\"../final_data/all_train_unsc.pkl\")\n",
    "\n",
    "train_norm = pd.read_pickle(\"../final_data/train_norm.pkl\")\n",
    "valid_norm = pd.read_pickle(\"../final_data/valid_norm.pkl\")\n",
    "test_norm = pd.read_pickle(\"../final_data/test_norm.pkl\")\n",
    "all_train_norm = pd.read_pickle(\"../final_data/all_train_norm.pkl\")\n",
    "\n",
    "cc4_data = pd.read_pickle(\"../final_data/cc4_data.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model LSTM Dropout Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../final_data/models/LSTMDropout_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to look at single sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform data so that for each sequence we have measured values and prediction separately\n",
    "\n",
    "## transform into (samples, time steps, features) format\n",
    "def lstm_format(data):\n",
    "    length_cc4 = 15.42\n",
    "    seq_len = 50  #only 5 time steps in the past\n",
    "    features = []\n",
    "    labels = []\n",
    "    data_set = {}\n",
    "\n",
    "    for _, group in data.groupby('seq_id'):\n",
    "        for i in range(len(group)-(seq_len-1)):\n",
    "            features.append(group[feature_keys].iloc[i:i+seq_len].to_numpy())  \n",
    "            labels.append(group[label_keys].iloc[i+(seq_len-1)].to_numpy())\n",
    "\n",
    "    data_set['x'] = np.stack(features)\n",
    "    data_set['y'] = np.stack(labels)\n",
    "    return data_set\n",
    "\n",
    "test_seq = test_norm['seq_id'].drop_duplicates()\n",
    "\n",
    "x = {}\n",
    "y = {}\n",
    "for seq in test_seq:\n",
    "    df = lstm_format(test_norm[test_norm['seq_id']==seq])\n",
    "    x[seq]= df['x'].copy()\n",
    "    y[seq] = df['y'].copy()\n",
    "\n",
    "## predicted and measured values\n",
    "prediction = {}\n",
    "real_values = {}\n",
    "rmse = {}\n",
    "for seq in test_seq:\n",
    "    prediction[seq] = scaler_y.inverse_transform(model.predict(x[seq]))\n",
    "    real_values[seq] = scaler_y.inverse_transform(y[seq])\n",
    "    rmse[seq] = np.sqrt(mean_squared_error( prediction[seq],  real_values[seq]))  \n",
    "\n",
    "error = []\n",
    "for seq in test_seq:\n",
    "    error.append((rmse[seq], seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_keys = ['WasserZ4FsInLproMin_integr', 'WasserZ4LsInLproMin_integr',\n",
    "       'WasserZ2bFsInLproMin_integr', 'WasserZ2bLsInLproMin_integr',\n",
    "       'WasserZ3bFsInLproMin_integr', 'WasserZ1FsInLproMin_integr',\n",
    "       'WasserZ3bLsInLproMin_integr', 'WasserZ1LsInLproMin_integr',\n",
    "       'WasserZ3aFsInLproMin_integr', 'WasserZ3aLsInLproMin_integr',\n",
    "       'WasserZ2aLsInLproMin_integr', 'WasserZ2aFsInLproMin_integr',\n",
    "       'WasserZ5LsInLproMin_integr', 'WasserZ5FsInLproMin_integr',\n",
    "       \n",
    "             ]\n",
    "not_water_keys = [e for e in feature_keys if e not in water_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change values of specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function that plots the measured temperature, the original prediciton and the new prediction\n",
    "def new_predicition_plot(test_change_unsc, test_change_unsc_2, descr_change, descr_change_2):\n",
    "    id_test = test_change_unsc['seq_id'].to_frame()\n",
    "    id_test =id_test.reset_index(drop=True)\n",
    "\n",
    "    test_change_x = scaler_x.transform(test_change_unsc[feature_keys])\n",
    "    test_change_x = pd.DataFrame(test_change_x, columns=(feature_keys))\n",
    "    test_change_y = scaler_y.transform(test_change_unsc[label_keys])\n",
    "    test_change_y = pd.DataFrame(test_change_y, columns=(label_keys))\n",
    "\n",
    "    test_change = pd.concat([test_change_y,test_change_x],axis=1)\n",
    "    test_change = pd.concat([test_change,id_test],axis=1)\n",
    "    test_change = test_change.reset_index(drop=True)\n",
    "\n",
    "    df = lstm_format(test_change)\n",
    "    x_change = df['x'].copy()\n",
    "\n",
    "    prediction_change = scaler_y.inverse_transform(model.predict(x_change))\n",
    "    rmse_change = np.sqrt(mean_squared_error(prediction_change, real_values[seq])) \n",
    "    print(\"new RMSE\",descr_change, \" :\" , rmse_change)\n",
    "    \n",
    "    test_change_x_2 = scaler_x.transform(test_change_unsc_2[feature_keys])\n",
    "    test_change_x_2 = pd.DataFrame(test_change_x_2, columns=(feature_keys))\n",
    "    test_change_y_2 = scaler_y.transform(test_change_unsc_2[label_keys])\n",
    "    test_change_y_2 = pd.DataFrame(test_change_y_2, columns=(label_keys))\n",
    "\n",
    "    test_change_2 = pd.concat([test_change_y_2,test_change_x_2],axis=1)\n",
    "    test_change_2 = pd.concat([test_change_2,id_test],axis=1)\n",
    "    test_change_2 = test_change_2.reset_index(drop=True)\n",
    "\n",
    "    df_2 = lstm_format(test_change_2)\n",
    "    x_change_2 = df_2['x'].copy()\n",
    "\n",
    "    prediction_change_2 = scaler_y.inverse_transform(model.predict(x_change_2))\n",
    "    rmse_change_2 = np.sqrt(mean_squared_error(prediction_change_2, real_values[seq]  )) \n",
    "    print(\"new RMSE\",descr_change_2, \" :\" , rmse_change_2)\n",
    "    \n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "    ax1.plot(real_values[seq][:,:1], color='black', label='measured')\n",
    "    ax1.plot(prediction[seq][:,:1], color='blue', label='original predicted')\n",
    "\n",
    "    ax1.plot(prediction_change[:,:1], color='red', label=descr_change)\n",
    "    ax1.plot(prediction_change_2[:,:1], color='green', label=descr_change_2)\n",
    "\n",
    "    ax1.set_xlabel('Minutes', fontsize=15)\n",
    "    ax1.set_ylabel('Temperature [Â°C]',fontsize=15)\n",
    "    ax1.xaxis.grid(True)\n",
    "   #ax1.yaxis.grid(True)\n",
    "    ax1.legend(loc='best', prop={'size': 13})\n",
    "    ax1.set(yticks=[])\n",
    "    ax1.set_ylim(660, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change casting target temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that can be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq = '473562_str_1'  ## choose sequence \n",
    "test_change_unsc = test_unsc[test_unsc['seq_id']==seq].copy() ##test data of chosen sequence\n",
    "test_change_unsc_2 = test_change_unsc.copy()\n",
    "\n",
    "features_changed =  ['WasserZ4FsInLproMin_integr', 'GiessLaengeSequenzInM_delta',\n",
    " 'WasserZ4LsInLproMin_integr']  ## choose features to change\n",
    "features_changed_2 = [] ## choose second features to change\n",
    "\n",
    "descr_change = \"high casting target temp\" ## description of first new prediction in plot\n",
    "descr_change_2 = \"low casting target temp\" ## description of second new prediction in plot\n",
    "\n",
    "for col in features_changed:\n",
    "    test_change_unsc[col].values[:] = cc4_data[col].mean()/2\n",
    "    test_change_unsc['GiessLaengeSequenzInM_delta'].values[:] = cc4_data[col].mean()/2\n",
    "    ## set value for each feature\n",
    "    test_change_unsc_2[col].values[:] = cc4_data[col].mean() \n",
    "    \n",
    "new_predicition_plot(test_change_unsc, test_change_unsc_2, descr_change, descr_change_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change cooling water quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All cooling water features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_keys = ['WasserZ4FsInLproMin_integr',\n",
    " 'WasserZ4LsInLproMin_integr',\n",
    " 'WasserZ2bFsInLproMin_integr',\n",
    " 'WasserZ2bLsInLproMin_integr',\n",
    " 'WasserZ3bFsInLproMin_integr',\n",
    " 'WasserZ1FsInLproMin_integr',\n",
    " 'WasserZ3bLsInLproMin_integr',\n",
    " 'WasserZ1LsInLproMin_integr',\n",
    " 'WasserZ3aFsInLproMin_integr',\n",
    " 'WasserZ3aLsInLproMin_integr',\n",
    " 'WasserZ2aLsInLproMin_integr',\n",
    " 'WasserZ2aFsInLproMin_integr',\n",
    " 'WasserZ5LsInLproMin_integr',\n",
    " 'WasserZ5FsInLproMin_integr',\n",
    "                  'GiessLaengeSequenzInM_delta',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq = '473562_str_1'  ## choose sequence \n",
    "test_change_unsc = test_unsc[test_unsc['seq_id']==seq].copy() ##test data of chosen sequence\n",
    "test_change_unsc_2 = test_change_unsc.copy()\n",
    "\n",
    "features_changed =  together_keys  ## choose features to change\n",
    "features_changed_2 = together_keys ## choose second features to change\n",
    "\n",
    "descr_change = \"high cooling water all zones\" ## description of first new prediction in plot\n",
    "descr_change_2 = \"low cooling water all zones\" ## description of second new prediction in plot\n",
    "\n",
    "for col in features_changed:\n",
    "    test_change_unsc[col].values[:] = cc4_data[col].mean()*2.5  ## set value for each feature\n",
    "    test_change_unsc[ 'GiessLaengeSequenzInM_delta'].values[:] = cc4_data['GiessLaengeSequenzInM_delta'].mean()/2.5\n",
    "    test_change_unsc_2[col].values[:] = cc4_data[col].mean()/3.5\n",
    "    test_change_unsc_2[ 'GiessLaengeSequenzInM_delta'].values[:] = cc4_data['GiessLaengeSequenzInM_delta'].mean()*3.5\n",
    "    \n",
    "new_predicition_plot(test_change_unsc, test_change_unsc_2, descr_change, descr_change_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = '473562_str_1'  ## choose sequence \n",
    "test_change_unsc = test_unsc[test_unsc['seq_id']==seq].copy() ##test data of chosen sequence\n",
    "test_change_unsc_2 = test_change_unsc.copy()\n",
    "\n",
    "features_changed =  together_keys  ## choose features to change\n",
    "features_changed_2 = together_keys ## choose second features to change\n",
    "\n",
    "descr_change = \"high cooling water low speed\" ## description of first new prediction in plot\n",
    "descr_change_2 = \"low cooling water high speed\" ## description of second new prediction in plot\n",
    "\n",
    "for col in features_changed:\n",
    "    test_change_unsc[col].values[:] = cc4_data[col].mean()*2.5  ## set value for each feature\n",
    "    test_change_unsc[ 'GiessLaengeSequenzInM_delta'].values[:] = cc4_data['GiessLaengeSequenzInM_delta'].mean()/2.5\n",
    "    test_change_unsc_2[col].values[:] = cc4_data[col].mean()/3.5\n",
    "    test_change_unsc_2[ 'GiessLaengeSequenzInM_delta'].values[:] = cc4_data['GiessLaengeSequenzInM_delta'].mean()*3.5\n",
    "    \n",
    "\n",
    "id_test = test_change_unsc['seq_id'].to_frame()\n",
    "id_test =id_test.reset_index(drop=True)\n",
    "\n",
    "test_change_x = scaler_x.transform(test_change_unsc[feature_keys])\n",
    "test_change_x = pd.DataFrame(test_change_x, columns=(feature_keys))\n",
    "test_change_y = scaler_y.transform(test_change_unsc[label_keys])\n",
    "test_change_y = pd.DataFrame(test_change_y, columns=(label_keys))\n",
    "\n",
    "test_change = pd.concat([test_change_y,test_change_x],axis=1)\n",
    "test_change = pd.concat([test_change,id_test],axis=1)\n",
    "test_change = test_change.reset_index(drop=True)\n",
    "\n",
    "df = lstm_format(test_change)\n",
    "x_change = df['x'].copy()\n",
    "\n",
    "prediction_change = scaler_y.inverse_transform(model.predict(x_change))\n",
    "rmse_change = np.sqrt(mean_squared_error(prediction_change, real_values[seq])) \n",
    "print(\"new RMSE\",descr_change, \" :\" , rmse_change)\n",
    "\n",
    "test_change_x_2 = scaler_x.transform(test_change_unsc_2[feature_keys])\n",
    "test_change_x_2 = pd.DataFrame(test_change_x_2, columns=(feature_keys))\n",
    "test_change_y_2 = scaler_y.transform(test_change_unsc_2[label_keys])\n",
    "test_change_y_2 = pd.DataFrame(test_change_y_2, columns=(label_keys))\n",
    "\n",
    "test_change_2 = pd.concat([test_change_y_2,test_change_x_2],axis=1)\n",
    "test_change_2 = pd.concat([test_change_2,id_test],axis=1)\n",
    "test_change_2 = test_change_2.reset_index(drop=True)\n",
    "\n",
    "df_2 = lstm_format(test_change_2)\n",
    "x_change_2 = df_2['x'].copy()\n",
    "\n",
    "prediction_change_2 = scaler_y.inverse_transform(model.predict(x_change_2))\n",
    "rmse_change_2 = np.sqrt(mean_squared_error(prediction_change_2, real_values[seq]  )) \n",
    "print(\"new RMSE\",descr_change_2, \" :\" , rmse_change_2)\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "ax1.plot(real_values[seq][:,:1], color='black', label='measured')\n",
    "ax1.plot(prediction[seq][:,:1], color='blue', label='original predicted')\n",
    "\n",
    "ax1.plot(prediction_change[:,:1], color='red', label=descr_change)\n",
    "ax1.plot(prediction_change_2[:,:1], color='green', label=descr_change_2)\n",
    "\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [Â°C]',fontsize=15)\n",
    "ax1.xaxis.grid(True)\n",
    "#ax1.yaxis.grid(True)\n",
    "ax1.legend(loc='best', prop={'size': 13})\n",
    "#ax1.set(yticks=[])\n",
    "ax1.set_ylim(660, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/home/di40438/bachelorarbeit/data/water_speed_dill.png', format='png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_change_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_change_unsc_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes for each Zone \n",
    "Here only for no water in first 4 zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = '473562_str_1'\n",
    "test_change_3_unsc = test_unsc[test_unsc['seq_id']==seq].copy()\n",
    "features_changed_3 =  ['WasserZ1LsInLproMin_integr',\n",
    " 'WasserZ1FsInLproMin_integr'] \n",
    "\n",
    "for col in features_changed_3:\n",
    "    test_change_3_unsc[col].values[:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_change_low_1 = pd.read_pickle(\"../final_data/sensitivity/low_water_z1.pkl\")\n",
    "prediction_change_low_2a = pd.read_pickle(\"../final_data/sensitivity/low_water_z2a.pkl\")\n",
    "prediction_change_low_2b = pd.read_pickle(\"../final_data/sensitivity/low_water_z2b.pkl\")\n",
    "prediction_change_low_3a = pd.read_pickle(\"../final_data/sensitivity/low_water_z3a.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = test_change_3_unsc['seq_id'].to_frame()\n",
    "id_test =id_test.reset_index(drop=True)\n",
    "\n",
    "test_change_3_x = scaler_x.transform(test_change_3_unsc[feature_keys])\n",
    "test_change_3_x = pd.DataFrame(test_change_3_x, columns=(feature_keys))\n",
    "test_change_3_y = scaler_y.transform(test_change_3_unsc[label_keys])\n",
    "test_change_3_y = pd.DataFrame(test_change_3_y, columns=(label_keys))\n",
    "\n",
    "test_change_3 = pd.concat([test_change_3_y,test_change_3_x],axis=1)\n",
    "test_change_3 = pd.concat([test_change_3,id_test],axis=1)\n",
    "test_change_3 = test_change_3.reset_index(drop=True)\n",
    "\n",
    "df = lstm_format(test_change_3)\n",
    "x_change_3= df['x'].copy()\n",
    "\n",
    "prediction_change_3 = scaler_y.inverse_transform(model.predict(x_change_3))\n",
    "rmse_change_3 = np.sqrt(mean_squared_error( prediction_change_3, real_values[seq]  ))  \n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "ax1.plot(real_values[seq][:,:1], color='black', label='measured')\n",
    "ax1.plot(prediction[seq][:,:1], color='blue', label='original predicted')\n",
    "ax1.plot(prediction_change_low_1.iloc[:,:1],'red',  label='Z1 low')\n",
    "ax1.plot(prediction_change_low_2a.iloc[:,:1],'orange',  label='Z2a low')\n",
    "ax1.plot(prediction_change_low_2b.iloc[:,:1],'green',  label='Z2b low')\n",
    "ax1.plot(prediction_change_low_3a.iloc[:,:1],'m',  label='Z3a low')\n",
    "\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [Â°C]',fontsize=15)\n",
    "ax1.set_ylim(660, 800)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.legend(loc='best', prop={'size': 13})\n",
    "#ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_change_low_1 = prediction_change_3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change casting speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planned Casting Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq = '473562_str_1'  ## choose sequence \n",
    "test_change_unsc = test_unsc[test_unsc['seq_id']==seq].copy() ##test data of chosen sequence\n",
    "test_change_unsc_2 = test_change_unsc.copy()\n",
    "\n",
    "features_changed =  ['SollGiessGeschwInMproMin']   ## choose features to change\n",
    "features_changed_2 = ['SollGiessGeschwInMproMin'] ## choose second features to change\n",
    "\n",
    "descr_change = \"high casting speed\" ## description of first new prediction in plot\n",
    "descr_change_2 = \"low casting speed\" ## description of second new prediction in plot\n",
    "\n",
    "for col in features_changed:\n",
    "    test_change_unsc[col].values[:] = cc4_data[col].max()*1.5   ## set value for each feature\n",
    "    test_change_unsc_2[col].values[:] = cc4_data[col].min()/1.5 \n",
    "    \n",
    "new_predicition_plot(test_change_unsc, test_change_unsc_2, descr_change, descr_change_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Casting Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = '473562_str_1'  ## choose sequence \n",
    "test_change_unsc = test_unsc[test_unsc['seq_id']==seq].copy() ##test data of chosen sequence\n",
    "test_change_unsc_2 = test_change_unsc.copy()\n",
    "\n",
    "features_changed =  ['GiessLaengeSequenzInM_delta']   ## choose features to change\n",
    "features_changed_2 = ['GiessLaengeSequenzInM_delta'] ## choose second features to change\n",
    "\n",
    "descr_change = \"high casting speed\" ## description of first new prediction in plot\n",
    "descr_change_2 = \"low casting speed\" ## description of second new prediction in plot\n",
    "\n",
    "for col in features_changed:\n",
    "    test_change_unsc[col].values[:] = cc4_data[col].max()*1.5   ## set value for each feature\n",
    "    test_change_unsc_2[col].values[:] = cc4_data[col].min() \n",
    "    \n",
    "new_predicition_plot(test_change_unsc, test_change_unsc_2, descr_change, descr_change_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changes to average predicted temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of new predicted temperature for whole test set\n",
    "Here for casting target temperature as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set values to change\n",
    "all_test_change_unsc = test_unsc.copy()\n",
    "features_changed = ['ZielTempTreiberInC']\n",
    "for col in features_changed:\n",
    "    all_test_change_unsc[col].values[:] = cc4_data[col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = all_test_change_unsc['seq_id'].to_frame()\n",
    "id_test =id_test.reset_index(drop=True)\n",
    "\n",
    "test_change_x = scaler_x.transform(all_test_change_unsc[feature_keys])\n",
    "test_change_x = pd.DataFrame(test_change_x, columns=(feature_keys))\n",
    "test_change_y = scaler_y.transform(all_test_change_unsc[label_keys])\n",
    "test_change_y = pd.DataFrame(test_change_y, columns=(label_keys))\n",
    "\n",
    "test_change = pd.concat([test_change_y,test_change_x],axis=1)\n",
    "test_change = pd.concat([test_change,id_test],axis=1)\n",
    "test_change = test_change.reset_index(drop=True)\n",
    "\n",
    "df = lstm_format(test_change)\n",
    "x_change= df['x'].copy()\n",
    "\n",
    "prediction_change = scaler_y.inverse_transform(model.predict(x_change))\n",
    "print('Mean of new predicted temperature for whole test set:')\n",
    "prediction_change.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of original predicted temperature for whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_prediction = scaler_y.inverse_transform(model.predict(test_x))\n",
    "print('Mean of original predicted temperature for whole test set:')\n",
    "original_prediction.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of original predicted temperature for a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = test_change['seq_id'].drop_duplicates()  ## als sequence ids in test set\n",
    "\n",
    "x_all_changed = {}\n",
    "y_all_changed = {}\n",
    "for seq in test_seq:\n",
    "    df = lstm_format(test_change[test_change['seq_id']==seq])\n",
    "    x_all_changed[seq]= df['x'].copy()\n",
    "    y_all_changed[seq] = df['y'].copy()\n",
    "mean_temp = []\n",
    "prediction_all_changed = {}  ## new predictions for each sequence in test set\n",
    "for seq in test_seq:\n",
    "    prediction_all_changed[seq] = scaler_y.inverse_transform(model.predict(x_all_changed[seq]))\n",
    "    mean_temp.append(prediction_all_changed[seq].mean())\n",
    "    \n",
    "print('Mean of new predicted temperature for each sequences:')\n",
    "np.mean(mean_temp)  ##mean over all sequences in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_prediciton = []\n",
    "for seq in test_seq:\n",
    "     mean_prediciton.append(prediction[seq].mean())\n",
    "        \n",
    "print('Mean of original predicted temperature for each sequences:')\n",
    "np.mean(mean_prediciton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Properties of a single sequence after changes were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose sequences\n",
    "seq_number = '473562_str_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cooling water curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1, figsize=(6, 5))\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ5LsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z5')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ4LsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z4')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ3bLsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z3b')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ3aLsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z3a')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ2bLsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z2b')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ2aLsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z2a')\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True),\n",
    "             y='WasserZ1LsInLproMin_integr',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][50:].reset_index(drop=True).index,\n",
    "             ax=ax1, label='cooling water Z1')\n",
    "ax1.set_ylabel('Cooling Water [l]', fontsize=15)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.legend(loc='upper left', prop={'size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting speed curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, figsize=(6, 5))\n",
    "sns.lineplot(data=test_change_unsc[test_change_unsc['seq_id']==seq_number][5:].reset_index(drop=True),\n",
    "             y='GiessLaengeSequenzInM_delta',x=test_change_unsc[test_change_unsc['seq_id']==seq_number][5:].reset_index(drop=True).index,\n",
    "             ax=ax1, color='black')\n",
    "ax1.set_xlabel('Minutes', fontsize=15  )\n",
    "ax1.set_ylabel('Casting Speed [m/min]', fontsize=15 )\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model without specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_used = ['ZielTempTreiberInC']  ## exclude feature\n",
    "new_features = [e for e in feature_keys if e not in not_used]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data in LSTM format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_format_new_features(data):\n",
    "    length_cc4 = 15.42\n",
    "    seq_len = 50\n",
    "    features = []\n",
    "    labels = []\n",
    "    data_set = {}\n",
    "\n",
    "    for _, group in data.groupby('seq_id'):\n",
    "        for i in range(len(group)-(seq_len-1)):\n",
    "            features.append(group[new_features].iloc[i:i+seq_len].to_numpy())  \n",
    "            labels.append(group[label_keys].iloc[i+(seq_len-1)].to_numpy())\n",
    "\n",
    "    data_set['x'] = np.stack(features)\n",
    "    data_set['y'] = np.stack(labels)\n",
    "    return data_set\n",
    "\n",
    "test_n = lstm_format_new_features(test_norm)\n",
    "test_x_norm = test_n['x'].copy()\n",
    "test_y_norm = test_n['y'].copy()\n",
    "\n",
    "all_train_n = lstm_format_new_features(all_train_norm)\n",
    "all_train_x_norm = all_train_n['x'].copy()\n",
    "all_train_y_norm = all_train_n['y'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the best LSTM model with new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMDropout_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(16,\n",
    "#                       input_shape=(all_train_x_norm.shape[1],all_train_x_norm.shape[2]),\n",
    "#                       return_sequences=True,\n",
    "#                       dropout=0.3,\n",
    "#                       recurrent_dropout=0.3,\n",
    "#                       kernel_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                       recurrent_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                       ),\n",
    "    \n",
    "#     keras.layers.LSTM(16,\n",
    "#                     return_sequences=True,\n",
    "#                     dropout=0.3,\n",
    "#                     recurrent_dropout=0.3,\n",
    "#                     kernel_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                     recurrent_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                      ),\n",
    "    \n",
    "#     keras.layers.LSTM(16,\n",
    "#                     return_sequences=False,\n",
    "#                     dropout=0.3,\n",
    "#                     recurrent_dropout=0.3,\n",
    "#                     kernel_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                     recurrent_constraint=keras.constraints.max_norm(max_value=1),\n",
    "#                     ),\n",
    "    \n",
    "#     keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "# ])\n",
    "\n",
    "# LSTMDropout_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "# LSTMDropout_model.summary()\n",
    "\n",
    "\n",
    "# LSTMDropout_history = LSTMDropout_model.fit(all_train_x_norm, all_train_y_norm,\n",
    "#                     epochs=99,\n",
    "#                     batch_size=128, \n",
    "#                     verbose=2\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_lstm = keras.models.load_model(\"../final_data/models/lstm_no_casting_target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE of new Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test= new_lstm.predict(test_x_norm)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y_norm)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "print('RMSE of new model:')\n",
    "np.sqrt(mean_squared_error(y_pred_test_unsc, y_test_unsc))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect to prediction of a single sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring data in the LSTM format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_format(data):\n",
    "    length_cc4 = 15.42\n",
    "    seq_len = 50\n",
    "    features = []\n",
    "    labels = []\n",
    "    data_set = {}\n",
    "\n",
    "    for _, group in data.groupby('seq_id'):\n",
    "        for i in range(len(group)-(seq_len-1)):\n",
    "            features.append(group[new_features].iloc[i:i+seq_len].to_numpy())   ##Achtung keys wieder Ã¤ndern!\n",
    "            labels.append(group[label_keys].iloc[i+(seq_len-1)].to_numpy())\n",
    "\n",
    "    data_set['x'] = np.stack(features)\n",
    "    data_set['y'] = np.stack(labels)\n",
    "    return data_set\n",
    "\n",
    "test_seq = test_norm['seq_id'].drop_duplicates()\n",
    "\n",
    "x = {}\n",
    "y = {}\n",
    "for seq in test_seq:\n",
    "    df = lstm_format(test_norm[test_norm['seq_id']==seq])\n",
    "    x[seq]= df['x'].copy()\n",
    "    y[seq] = df['y'].copy()\n",
    "\n",
    "prediction = {}\n",
    "real_values = {}\n",
    "rmse = {}\n",
    "for seq in test_seq:\n",
    "    prediction[seq] = scaler_y.inverse_transform(new_lstm.predict(x[seq]))\n",
    "    real_values[seq] = scaler_y.inverse_transform(y[seq])\n",
    "    rmse[seq] = np.sqrt(mean_squared_error( prediction[seq],  real_values[seq]))  \n",
    "\n",
    "error = []\n",
    "for seq in test_seq:\n",
    "    error.append((rmse[seq], seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at new prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sequences_name = '473562_str_1'\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "ax1.plot(real_values[sequences_name][:,:1], color='black', label='Measured Temperature')\n",
    "ax1.plot(prediction[sequences_name][:,:1], color='blue', label='Predicted Temperature')\n",
    "ax1.legend(loc='best')\n",
    "#ax1.set_title('Comparison Between Measured and Predicted Temperatures for Sequence '+str(sequences_name))\n",
    "ax1.set_ylabel('Temperature')\n",
    "ax1.tick_params(axis='both', which='both', labelbottom=True)\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [Â°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "\n",
    "print('RMSE:', rmse[sequences_name] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
