{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import kerastuner as kt\n",
    "import pickle\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from numpy import load\n",
    "from numpy import save\n",
    "from tensorflow.keras import regularizers\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = pd.read_pickle(\"../final_data/train_norm.pkl\")\n",
    "valid_norm = pd.read_pickle(\"../final_data/valid_norm.pkl\")\n",
    "test_norm = pd.read_pickle(\"../final_data/test_norm.pkl\")\n",
    "all_train_norm = pd.read_pickle(\"../final_data/all_train_norm.pkl\")\n",
    "\n",
    "scaler_x = joblib.load(\"../final_data/scaler_x.save\") \n",
    "scaler_y = joblib.load(\"../final_data/scaler_y.save\") \n",
    "\n",
    "scaler_train_x = joblib.load(\"../final_data/scaler_train_x.save\") \n",
    "scaler_train_y = joblib.load(\"../final_data/scaler_train_y.save\")\n",
    "\n",
    "train_data = pd.read_pickle(\"../final_data/train_unsc.pkl\")\n",
    "valid_data = pd.read_pickle(\"../final_data/valid_unsc.pkl\")\n",
    "test_data = pd.read_pickle(\"../final_data/test_unsc.pkl\")\n",
    "all_train_data = pd.read_pickle(\"../final_data/all_train_unsc.pkl\")\n",
    "\n",
    "with open ('../final_data/label_keys_ts', 'rb') as fp:\n",
    "    label_keys = pickle.load(fp)\n",
    "with open ('../final_data/feature_keys_ts', 'rb') as fp:\n",
    "    feature_keys = pickle.load(fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_x = all_train_norm[feature_keys]\n",
    "all_train_y = all_train_norm[label_keys]\n",
    "test_x = test_norm[feature_keys]\n",
    "test_y = test_norm[label_keys]\n",
    "valid_x = valid_norm[feature_keys]\n",
    "valid_y = valid_norm[label_keys]\n",
    "train_x = train_norm[feature_keys]\n",
    "train_y = train_norm[label_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_unsc = all_train_data[feature_keys]\n",
    "train_y_unsc = all_train_data[label_keys]\n",
    "test_x_unsc = test_data[feature_keys]\n",
    "test_y_unsc = test_data[label_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_base = test_y_unsc.copy()\n",
    "train_pred_base['TempMittelLsInC'] = train_pred_base['TempMittelLsInC'].mean(axis=0)\n",
    "train_pred_base['TempMittelFsInC'] = train_pred_base['TempMittelFsInC'].mean(axis=0)\n",
    "train_pred_base = train_pred_base.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_y_unsc.to_numpy(), train_pred_base)                             \n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_10_times(model, epochs, batch_size):\n",
    "    runs = 10\n",
    "    test_score = list()\n",
    "    train_score = list()\n",
    " \n",
    "    for i in range(runs):\n",
    "\n",
    "        np.random.seed(123 + i)\n",
    "        tf.random.set_seed(123 + i)\n",
    "\n",
    "\n",
    "\n",
    "        history = model.fit(all_train_x, all_train_y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                       )\n",
    "\n",
    "        y_pred_test = model.predict(test_x)\n",
    "        y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "        y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "        y_pred_train = model.predict(all_train_x)\n",
    "        y_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "        y_pred_train_unsc = scaler_y.inverse_transform(y_pred_train)\n",
    "        \n",
    "        mse_test = np.sqrt(mean_squared_error(y_pred_test_unsc, y_test_unsc))  \n",
    "        test_score.append(mse_test)\n",
    "\n",
    "        mse_train = np.sqrt(mean_squared_error(y_pred_train_unsc, y_train_unsc))  \n",
    "        train_score.append(mse_train)\n",
    "\n",
    "    return  train_score, test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model_simple_mlp():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:]),\n",
    "        keras.layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = build_model_simple_mlp()\n",
    "history_simple_model = simple_model.fit(train_x, train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp_ts = keras.models.load_model(\"/home/di40438/bachelorarbeit/final_data/simple_mlp_ts_train\")\n",
    "hist_simple_mlp_ts = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/hist_simple_mlp_ts_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_mlp_ts).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance after applying early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate RMSE on training set\n",
    "y_pred_train = simple_mlp_ts.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate RMSE on validation set\n",
    "y_pred_val = simple_mlp_ts.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = build_model_simple_mlp()\n",
    "\n",
    "history_simple_model = simple_model.fit(all_train_x, all_train_y,\n",
    "                    epochs=87,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_test = keras.models.load_model(\"/home/di40438/bachelorarbeit/final_data/models/simple_mlp_ts_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate RMSE on test set\n",
    "y_pred_test = simple_model_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = build_model_simple_mlp()\n",
    "epochs = 87\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(simple_model, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_simple_mlp_ts = pd.read_pickle(\"../final_data/rmse_train_simple_mlp_ts.pkl\")\n",
    "rmse_test_simple_mlp_ts = pd.read_pickle(\"../final_data/rmse_test_mlp_ts_simple_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_simple_mlp_ts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_simple_mlp_ts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model_simple_dropout():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:]),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "                 \n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                  \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "model_simple_dropout = build_model_simple_dropout()\n",
    "\n",
    "history_simple_dropout = model_simple_dropout.fit(train_x, train_y,\n",
    "                    epochs=100,                         \n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_dropout = pd.read_pickle(\"../final_data/hist_simple_mlp_ts_drop.pkl\")\n",
    "model_simple_dropout = keras.models.load_model(\"../final_data/models/simple_mlp_ts_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_dropout).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_simple_dropout.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_simple_dropout.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model with weight regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "def build_model_simple_weight_reg():\n",
    "    model_kernel = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:],\n",
    "                          kernel_regularizer=regularizers.l2(1e-4)),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_kernel.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                 \n",
    "                 )\n",
    "    return model_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "model_simple_weight_reg = build_model_simple_weight_reg()\n",
    "history_simple_weight_reg = model_simple_weight_reg.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_weight_reg = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/hist_simple_mlp_ts_weight.pkl\")\n",
    "model_simple_weight_reg = keras.models.load_model(\"/home/di40438/bachelorarbeit/final_data/models/simple_mlp_ts_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_weight_reg).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_simple_weight_reg.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_simple_weight_reg.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "def build_model_dropout_tuned():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal',\n",
    "                           input_shape=train_x.shape[1:],\n",
    "                           kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal',\n",
    "                          kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal',\n",
    "                           kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',       \n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),         \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "model_dropout = build_model_dropout_tuned()\n",
    "history_dropout_model = model_dropout.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback],\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_model_dropout_train = pd.read_pickle(\"../final_data/hist_mlp_ts_dropout.pkl\")\n",
    "model_dropout_train = keras.models.load_model(\"../final_data/models/mlp_ts_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_model_dropout_train).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_dropout_train.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_dropout_train.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dropout_test = build_model_dropout_tuned()\n",
    "\n",
    "history_model_dropout_test = model_dropout_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=206,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout_test = keras.models.load_model(\"../final_data/models/mlp_ts_dropout_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = model_dropout_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = build_model_dropout_tuned()\n",
    "epochs = 206\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(model_dropout, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_model_dropout = pd.read_pickle(\"../final_data/rmse_train_model_dropout.pkl\")\n",
    "rmse_test_model_dropout = pd.read_pickle(\"../final_data/rmse_test_model_dropout.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_model_dropout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_model_dropout.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Dropout Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tuner implementation of Hyperband\n",
    "Hyperparameter search may take a while even with limited data, resulting architectur when used with all data is provided next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP with Dropout\n",
    "def model_builder_mlp (hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "   \n",
    "    hp_max_norm = hp.Choice(\"max_norm\",values = [0, 1, 2])\n",
    "    hp_units = hp.Choice(\"unit\",values = [16, 32, 64, 128, 192 ]) \n",
    "    hp_dropout = hp.Choice(\"mlp_layer_dropout\",values = [ 0.2, 0.3])\n",
    "    hp_number_of_layers = hp.Int(\"layers\",min_value=0,max_value=3,step=1)\n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "                            units= hp_units,\n",
    "                            kernel_constraint=keras.constraints.max_norm(max_value=hp_max_norm),                    \n",
    "                            activation='relu',\n",
    "                            input_shape=train_x.shape[1:]     \n",
    "                     ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(hp_dropout))\n",
    "    \n",
    "    for i in range(hp_number_of_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units = hp_units,\n",
    "                        kernel_constraint=keras.constraints.max_norm(max_value=hp_max_norm),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_normal'\n",
    "                        ))\n",
    "        \n",
    "        model.add(keras.layers.Dropout(hp_dropout))\n",
    "    \n",
    "    model.add(keras.layers.Dense(2, kernel_initializer='he_normal'))\n",
    "        \n",
    "    mlp_learning_rate = hp.Choice('learning_rate', values = [ 1e-3, 1e-4])\n",
    "    optimizer = keras.optimizers.Adam(lr=mlp_learning_rate)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "class MyTuner(kt.tuners.Hyperband):\n",
    "  def run_trial(self, trial, *args, **kwargs):\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\",values = [32, 128, 512])\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = MyTuner(model_builder_mlp,\n",
    "#                 objective='val_loss',\n",
    "#                 max_epochs = 100,\n",
    "#                 factor = 3,\n",
    "#                 seed = 42,\n",
    "#                 directory = \"k\",\n",
    "#                 project_name = 'k1')\n",
    "\n",
    "\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# tuner.search(train_x,\n",
    "#              train_y,\n",
    "#              epochs = 150,\n",
    "#              validation_data = (valid_x, valid_y),\n",
    "#              callbacks = [stop_early]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Either: Keras Tuner implementation of Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hyper_dropout = pickle.load(open(\"/home/di40438/bachelorarbeit/final_data/models/mlp_ts_drop_hyper.pkl\",'rb'))\n",
    "\n",
    "print(tuner_hyper_dropout.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_dropout.get_best_hyperparameters(num_trials=1)[0]\n",
    "hypermodel_dropout = tuner_hyper_dropout.hypermodel.build(best_hps)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "# Retrain the model\n",
    "history_hypermodel_dropout = hypermodel_dropout.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: Rebuild best Hyperband model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "def build_hypermodel_dropout():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                           input_shape=train_x.shape[1:],\n",
    "                           kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                          kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.2),\n",
    "\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),     \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "hypermodel_dropout = build_hypermodel_dropout()\n",
    "\n",
    "history_hypermodel_dropout = hypermodel_dropout.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_hypermodel_dropout_train = pd.read_pickle(\"../final_data/hist_hyper_mlp_ts_drop_train.pkl\")\n",
    "hypermodel_dropout_train = keras.models.load_model(\"../final_data/models/hyper_mlp_ts_drop_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_hypermodel_dropout_train).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = hypermodel_dropout_train.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = hypermodel_dropout_train.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Either: rebuild Keras Tuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_dropout.get_best_hyperparameters(num_trials=1)[0]\n",
    "hypermodel_dropout_test = tuner_hyper_dropout.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history_hypermodel_dropout = hypermodel_dropout_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=92,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: rebuild best model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel_dropout = build_hypermodel_dropout()\n",
    "\n",
    "history_hypermodel_dropout = hypermodel_dropout.fit(all_train_x, all_train_y,\n",
    "                    epochs=92,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel_dropout_test = keras.models.load_model(\"../final_data/models/hyper_mlp_ts_drop_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = hypermodel_dropout_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypermodel_dropout = build_hypermodel_dropout()\n",
    "epochs = 92\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(hypermodel_dropout, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_hyperband_dropout = pd.read_pickle(\"../final_data/rmse_train_mlp_ts_hyperband_dropout.pkl\")\n",
    "rmse_test_mlp_ts_hyperband_dropout = pd.read_pickle(\"../final_data/rmse_test_mlp_ts_hyperband_dropout.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_hyperband_dropout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_mlp_ts_hyperband_dropout.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with weight regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_weight_reg_tuned():\n",
    "    model_kernel = keras.models.Sequential([\n",
    "        keras.layers.Dense(48, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:],\n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                          \n",
    "                          ),\n",
    "        keras.layers.Dense(48, activation='relu',kernel_initializer='he_normal', \n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                         \n",
    "                          ),\n",
    "        keras.layers.Dense(48, activation='relu',kernel_initializer='he_normal', \n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       \n",
    "                          ),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_kernel.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                 \n",
    "                 )\n",
    "    return model_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_reg_train = build_model_weight_reg_tuned()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "history_model_weight_reg_train = model_weight_reg_train.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weigh_reg_train = pd.read_pickle(\"../final_data/hist_weigh_reg_train.pkl\")\n",
    "model_weight_reg_train = keras.models.load_model(\"../final_data/models/mlp_ts_weight_reg_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_weigh_reg_train).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_weight_reg_train.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_weight_reg_train.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_reg_test = build_model_weight_reg_tuned()\n",
    "\n",
    "model_weight_reg_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=147,\n",
    "                    batch_size=32,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_reg_test = keras.models.load_model(\"../final_data/models/mlp_ts_weight_reg_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_weight_reg_test.predict(all_train_x)\n",
    "y_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_train_unsc = scaler_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = model_weight_reg_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_weight_reg = build_model_weight_reg_tuned()\n",
    "epochs = 147\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(model_weight_reg, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_weight_reg = pd.read_pickle(\"../final_data/rmse_train_mlp_ts_weight_reg.pkl\")\n",
    "rmse_test_mlp_ts_weight_reg = pd.read_pickle(\"../final_data/rmse_test_mlp_ts_weight_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_weight_reg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_mlp_ts_weight_reg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Weight Regularization Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tuner implementation of Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_mlp (hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    hp_kernel_reg = hp.Choice(\"mlp_layer_kernel_reg\",values = [1e-3, 1e-4])\n",
    "    hp_units = hp.Choice(\"unit\",values = [16, 32, 64, 128, 192 ]) \n",
    "    hp_number_of_layers = hp.Choice(\"layers\",values = [0,1,2,3]) \n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "                            units= hp_units, \n",
    "                            kernel_regularizer=regularizers.l2(hp_kernel_reg),          \n",
    "                            activation='relu',\n",
    "                            input_shape=train_x.shape[1:]     \n",
    "                     ))\n",
    "\n",
    "    for i in range(hp_number_of_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units = hp_units,\n",
    "                        kernel_regularizer=regularizers.l2(hp_kernel_reg),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_normal'\n",
    "                        ))\n",
    "\n",
    "    model.add(keras.layers.Dense(2, kernel_initializer='he_normal'))\n",
    "        \n",
    "    mlp_learning_rate = hp.Choice('learning_rate', values = [ 1e-3, 1e-4])\n",
    "    optimizer = keras.optimizers.Adam(lr=mlp_learning_rate)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "              \n",
    "              \n",
    "class MyTuner(kt.tuners.Hyperband):\n",
    "  def run_trial(self, trial, *args, **kwargs):\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\",values = [32, 128, 512])\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only needs to be executed if Hyperband should search again, results can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner_hyper_weight = MyTuner(model_builder_mlp,\n",
    "#                    # optimizer=keras.optimizers.Adam(1e-3),\n",
    "#                     #loss='mean_squared_error',\n",
    "#                     objective='val_loss',\n",
    "#                     max_epochs = 100,\n",
    "#                     factor = 3,\n",
    "#                     seed = 42,\n",
    "#                     directory = \"../data/models\",\n",
    "#                     project_name = 'hyperband_mlp_ts_weight')\n",
    "\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# tuner_hyper_weight.search(train_x,\n",
    "#              train_y,\n",
    "#              epochs = 150,\n",
    "#              validation_data = (valid_x, valid_y),\n",
    "#              callbacks = [stop_early]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Either: Keras Tuner implementation of Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Tuner if Hyperband was not run, if Hyperband was run, do not execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hyper_weight = pickle.load(open(\"../final_data/models/hyper_mlp_ts_weight.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Hyperband was run execute here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuner_hyper_weight.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_weight.get_best_hyperparameters(num_trials=1)[0]\n",
    "hypermodel_weight_reg = tuner_hyper_weight.hypermodel.build(best_hps)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "# Retrain the model\n",
    "history_hypermodel_weight_reg = hypermodel_weight_reg.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: Rebuild best Hyperband model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hypermodel_weight_reg():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(320, activation='relu',kernel_initializer='he_normal',\n",
    "                           input_shape=train_x.shape[1:],\n",
    "                            kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dense(320, activation='relu',kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),     \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "hypermodel_weight_reg = build_hypermodel_weight_reg()\n",
    "\n",
    "history_hypermodel_weight_reg = hypermodel_weight_reg.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_hypermodel_weigh_reg_train = pd.read_pickle(\"../final_data/hist_hypermodel_mlp_ts_weight.pkl\")\n",
    "hypermodel_weight_reg_train = keras.models.load_model(\"../final_data/models/hypermodel_mlp_ts_weight_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_hypermodel_weigh_reg_train).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = hypermodel_weight_reg_train.predict(train_x)\n",
    "y_train_unsc = scaler_train_y.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_train_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = hypermodel_weight_reg_train.predict(valid_x)\n",
    "y_val_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_train_y.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Either: rebuild Keras Tuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_weight.get_best_hyperparameters(num_trials=1)[0]\n",
    "hypermodel_weight_reg = tuner_hyper_weight.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history_hypermodel_weight_reg = hypermodel_weight_reg.fit(all_train_x, all_train_y,\n",
    "                    epochs=109,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: rebuild best model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel_weight_reg = build_hypermodel_weight_reg()\n",
    "\n",
    "history_hypermodel_weight_reg = hypermodel_weight_reg.fit(all_train_x, all_train_y,\n",
    "                    epochs=109,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_reg_test = keras.models.load_model(\"../final_data/models/hyper_mlp_ts_weight_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = model_weight_reg_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypermodel_weight_reg = build_hypermodel_weight_reg()\n",
    "epochs = 109\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(hypermodel_dropout, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_hyperband_weight = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/rmse_train_mlp_ts_hyperband_weight.pkl\")\n",
    "rmse_test_mlp_ts_hyperband_weight = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/rmse_test_mlp_ts_hyperband_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_ts_hyperband_weight.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_mlp_ts_hyperband_weight.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not all models were run: Read saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_mlp_ts = pd.read_pickle(\"../final_data/hist_simple_mlp_ts_train.pkl\")\n",
    "hist_simple_dropout = pd.read_pickle(\"../final_data/hist_simple_mlp_ts_drop.pkl\")\n",
    "hist_simple_weight_reg = pd.read_pickle(\"../final_data/hist_simple_mlp_ts_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_simple_model = pd.read_pickle(\"../data/lstm_mlp/mlp_models/hist_simple_model.pkl\")\n",
    "# hist_simple_dropout = pd.read_pickle(\"../data/lstm_mlp/mlp_models/hist_simple_dropout.pkl\")\n",
    "# hist_model_simple_weight_reg = pd.read_pickle(\"../data/lstm_mlp/mlp_models/hist_model_simple_weight_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_simple_mlps, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(hist_simple_mlp_ts['loss'], label='SimpleMLP_Loss', color='dimgrey' )\n",
    "ax.plot(hist_simple_mlp_ts['val_loss'], label='SimpleMLP_Valid_Loss', color='black' )\n",
    "ax.plot(hist_simple_dropout['loss'], label='SimpleDropout_Loss', color='indianred')\n",
    "ax.plot(hist_simple_dropout['val_loss'], label='SimpleDropout_Valid_Loss', color='red')\n",
    "ax.plot(hist_simple_weight_reg['loss'], label='SimpleWeightReg_Loss', color='c')\n",
    "ax.plot(hist_simple_weight_reg['val_loss'], label='SimpleWeightReg_Valid_Loss', color='blue')\n",
    "ax.set_ylim(0.001, 0.005)\n",
    "ax.set(xlabel=' Epochs', ylabel='Score')\n",
    "ax.set_xlabel('Epochs', fontsize=15)\n",
    "ax.set_ylabel('Score', fontsize=15)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "ax.legend(loc='upper center',prop={'size': 12} )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not all models were run: Read saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_model_dropout_train = pd.read_pickle(\"../final_data/hist_mlp_ts_dropout.pkl\")\n",
    "hist_hypermodel_dropout_train = pd.read_pickle(\"../final_data/hist_hyper_mlp_ts_drop_train.pkl\")\n",
    "hist_weigh_reg_train = pd.read_pickle(\"../final_data/hist_weigh_reg_train.pkl\")\n",
    "hist_hypermodel_weigh_reg_train = pd.read_pickle(\"../final_data/hist_hypermodel_mlp_ts_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_final_mlps, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(hist_model_dropout_train['loss'], label='Dropout_Training', color='indianred' )\n",
    "ax.plot(hist_model_dropout_train['val_loss'], label='Dropout_Validation', color='red' )\n",
    "ax.plot(hist_hypermodel_dropout_train['loss'], label='HyperbandDropout_Training', color='dimgrey')\n",
    "ax.plot(hist_hypermodel_dropout_train['val_loss'], label='HyperbandDropout_Validation', color='black')\n",
    "ax.set_ylim(0.001, 0.003)\n",
    "ax.set(xlabel=' Epochs', ylabel='Score')\n",
    "ax.set_xlabel('Epochs', fontsize=15)\n",
    "ax.set_ylabel('Score', fontsize=15)\n",
    "plt.yticks(np.arange(0.001, 0.003+0.0005, 0.0005), fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "ax.legend(loc='upper right',prop={'size': 13} )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_final_mlps, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(hist_weigh_reg_train['loss'][:300], label='WeightReg_Training', color='c' )\n",
    "ax.plot(hist_weigh_reg_train['val_loss'][:300], label='WeightReg_Validation', color='blue' )\n",
    "ax.plot(hist_hypermodel_weigh_reg_train['loss'][:300], label='HyperbandWeightReg_Training', color='mediumseagreen')\n",
    "ax.plot(hist_hypermodel_weigh_reg_train['val_loss'][:300], label='HyperbandWeightReg_Validation', color='green')\n",
    "ax.set_ylim(0.001, 0.003)\n",
    "ax.set(xlabel=' Epochs', ylabel='Score')\n",
    "ax.set_xlabel('Epochs', fontsize=15)\n",
    "ax.set_ylabel('Score', fontsize=15)\n",
    "plt.yticks(np.arange(0.001, 0.003+0.0005, 0.0005), fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "ax.legend(loc='upper right',prop={'size': 13} )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_reg_train = keras.models.load_model(\"../final_data/models/mlp_ts_weight_reg_train\")\n",
    "model_weight_reg_test = keras.models.load_model(\"../final_data/models/mlp_ts_weight_reg_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use modell from training for validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid = model_weight_reg_train.predict(valid_x)\n",
    "y_valid_unsc = scaler_train_y.inverse_transform(valid_y)\n",
    "y_pred_valid_unsc = scaler_train_y.inverse_transform(y_pred_valid)\n",
    "np.sqrt(mean_squared_error(y_valid_unsc, y_pred_valid_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use model from testing for all_train and test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_weight_reg_test.predict(all_train_x)\n",
    "y_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_train_unsc = scaler_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_final = model_weight_reg_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc_final = scaler_y.inverse_transform(y_pred_test_final)\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc_final))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ig, ax1 = plt.subplots(1, figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_train_unsc, y_train_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.set(xticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_valid_unsc, y_valid_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.set(xticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,  figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_test_unsc_final, y_test_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set(xticks=[]) \n",
    "ax1.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at single sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get predicted and real value for each sequence seperately\n",
    "seq_ids = test_data.groupby('seq_id')    #group by each sequence+strand_r\n",
    "seq_id_test_data = list(seq_ids.groups.keys())\n",
    "\n",
    "df_temp_predicted = pd.DataFrame(y_pred_test_unsc_final, columns=['TempMittelLsInC_predicted','TempMittelFsInC_predicted'])\n",
    "df_pred = pd.concat([df_temp_predicted, test_data['seq_id']], axis=1)\n",
    "\n",
    "prediction = {}\n",
    "real_values = {}\n",
    "rmse = {}\n",
    "for seq in seq_id_test_data:\n",
    "    prediction[seq] = df_pred[['TempMittelLsInC_predicted', 'TempMittelFsInC_predicted']][df_pred['seq_id']==seq].to_numpy()\n",
    "    real_values[seq] = test_data[['TempMittelLsInC', 'TempMittelFsInC']][test_data['seq_id']\n",
    "                                                                                   ==seq].to_numpy()\n",
    "    rmse[seq] = np.sqrt(mean_squared_error( prediction[seq],  real_values[seq]))  \n",
    "\n",
    "error = []\n",
    "for seq in seq_id_test_data:\n",
    "    error.append((rmse[seq], seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '471949_str_1'\n",
    "fig1, (ax1) = plt.subplots(1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "\n",
    "ax1.plot(real_values[seq_number][:,:1], color='black', label='Measured Temperature')\n",
    "ax1.plot(prediction[seq_number][:,:1], color='blue', label='Predicted Temperature')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax1.set_ylim(600, 780)\n",
    "ax1.yaxis.grid(False)\n",
    "#ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(False)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '473562_str_1'\n",
    "fig2, (ax2) = plt.subplots(1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "\n",
    "ax2.plot(real_values[seq_number][:,1:2], color='black', label='Measured Temperature')\n",
    "ax2.plot(prediction[seq_number][:,1:2], color='blue', label='Predicted Temperature')\n",
    "ax2.legend(loc='best')\n",
    "ax2.grid()\n",
    "ax2.set_xlabel('Minutes', fontsize=15)\n",
    "ax2.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax2.set_ylim(600, 780)\n",
    "ax2.yaxis.grid(False)\n",
    "ax2.xaxis.grid(True)\n",
    "ax2.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '475401_str_1'\n",
    "fig3, (ax1) = plt.subplots(1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "\n",
    "ax1.plot(real_values[seq_number][:,:1], color='black', label='Measured Temperature')\n",
    "ax1.plot(prediction[seq_number][:,:1], color='blue', label='Predicted Temperature')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set_ylim(600, 780)\n",
    "ax1.yaxis.grid(False)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '474335_str_2'\n",
    "fig4, (ax1) = plt.subplots(1, figsize=(6, 5))\n",
    "sns.lineplot(data=pd.DataFrame(real_values[seq_number][:-1,1:2], columns=['Measured Temperature']),\n",
    "       palette=['black'],  ax=ax1 )\n",
    "sns.lineplot(data=pd.DataFrame(prediction[seq_number][:-1,1:2], columns=['Predicted Temperature']),\n",
    "          palette=['blue'],ax=ax1 )\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '472991_str_2'\n",
    "fig5, (ax1) = plt.subplots(1, figsize=(6, 5))\n",
    "sns.lineplot(data=pd.DataFrame(real_values[seq_number][:-1,1:2], columns=['Measured Temperature']),\n",
    "       palette=['black'],  ax=ax1 )\n",
    "sns.lineplot(data=pd.DataFrame(prediction[seq_number][:-1,1:2], columns=['Predicted Temperature']),\n",
    "          palette=['blue'],ax=ax1 )\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_number = '472885_str_2'\n",
    "fig6, (ax1) = plt.subplots(1, figsize=(6, 5),  sharex=True, sharey=True)\n",
    "\n",
    "ax1.plot(real_values[seq_number][:-1,:1], color='black', label='Measured Temperature')\n",
    "ax1.plot(prediction[seq_number][:-1,:1], color='blue', label='Predicted Temperature')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Minutes', fontsize=15)\n",
    "ax1.set_ylabel('Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.set(yticks=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
