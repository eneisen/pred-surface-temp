{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns\n",
    "import qgrid\n",
    "qgrid.set_grid_option('forceFitColumns', False)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path(\"../csv_data/\")\n",
    "\n",
    "data = {}\n",
    "for csv_file in data_dir.glob(\"*.csv\"):\n",
    "    if csv_file.stem in [\"schmelzen\", \"FormateCC4\"]:continue\n",
    "        \n",
    "    this_csv = pd.read_csv(csv_file, delimiter=\";\")\n",
    "    \n",
    "    this_csv['DATE_TIME'] = pd.to_datetime(this_csv['TIME'],unit='s').dt.tz_localize(\"UTC\")\n",
    "    this_csv = this_csv.set_index('DATE_TIME', drop=False).sort_index()\n",
    "    \n",
    "    data[csv_file.stem] = this_csv.sort_values(\"TIME\")\n",
    "    #display( data[csv_file.stem].tail())\n",
    "    \n",
    "data['TundishTemperaturInC'] = data['TundishTemperaturInC'][(data['TundishTemperaturInC']['TundishTemperaturInC'] < 1600) & (data['TundishTemperaturInC']['TundishTemperaturInC'] > 1400)]  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and further Preprocessing of schmelzen Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schmelzen = pd.read_pickle(\"../final_data/schmelzen.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_schmelzen = ['ChargenNr',\n",
    " 'ChargenNrErsteSchmInSeq',\n",
    " 'GiessBeginnSchmelze',\n",
    " 'GiessBeginn_DateTime',\n",
    " 'GiessEndeSchmelze',\n",
    " 'GiessEnde_DateTime',\n",
    " 'EndeSchmelze',\n",
    " 'Ende_DateTime',\n",
    " 'NrSchmelzeInSequenz',\n",
    " 'LiquidusTempInC',\n",
    " 'SolidusTempInC',\n",
    " 'UeberhitzungMittelInK',\n",
    " 'ZielTempTreiberInC',\n",
    " 'Str1SollGiessGeschwInMproMin',\n",
    " 'Str2SollGiessGeschwInMproMin',\n",
    " 'Str1Format',\n",
    " 'Str2Format',\n",
    " 'C-Aequiv01',\n",
    " 'C-Aequiv02',\n",
    " 'C-AequivP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 90 minutes to the end of the last melting process of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schmelzen['EndeSchmelze'] = df_schmelzen['GiessEndeSchmelze']\n",
    "\n",
    "df_schmelzen['ChargenNrErsteSchmInSeq_shifted'] = df_schmelzen['ChargenNrErsteSchmInSeq'].shift(-1)\n",
    "df_schmelzen = df_schmelzen.fillna(0)\n",
    "\n",
    "def add_time_to_end(row):               \n",
    "        if row['ChargenNrErsteSchmInSeq'] !=  row['ChargenNrErsteSchmInSeq_shifted']:\n",
    "            row['EndeSchmelze'] = row['EndeSchmelze'] + 90*60   #add 90 min to end of last 'GiessEnde' \n",
    "        return row\n",
    "\n",
    "df_schmelzen = df_schmelzen.apply(add_time_to_end, axis=1)\n",
    "\n",
    "df_schmelzen['Ende_DateTime'] = pd.to_datetime(df_schmelzen['EndeSchmelze'],unit='s').dt.tz_localize(\"UTC\")\n",
    "\n",
    "df_schmelzen = df_schmelzen.drop(\"ChargenNrErsteSchmInSeq_shifted\", axis=1)\n",
    "\n",
    "df_schmelzen = df_schmelzen[cols_schmelzen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine df_schmelzen and Laenge Sequenz with 90min added to 'GiessEnde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for _, row in data['Str1GiessLaengeSequenzInM'].iterrows():\n",
    "    schmelze = df_schmelzen[(df_schmelzen[\"GiessBeginn_DateTime\"] < row[\"DATE_TIME\"]) & (df_schmelzen[\"Ende_DateTime\"] >= row[\"DATE_TIME\"])]\n",
    "    if len(schmelze) != 1:\n",
    "        continue\n",
    "    merged.append(pd.concat([row.to_frame().transpose().reset_index(drop=True), schmelze.reset_index(drop=True)], axis=1))\n",
    "\n",
    "df_str1_extended = pd.concat(merged)\n",
    "df_str1_extended = df_str1_extended.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine df_schmelzen and Laenge Sequenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for _, row in data['Str1GiessLaengeSequenzInM'].iterrows():\n",
    "    schmelze = df_schmelzen[(df_schmelzen[\"GiessBeginn_DateTime\"] < row[\"DATE_TIME\"]) & (df_schmelzen[\"GiessEnde_DateTime\"] >= row[\"DATE_TIME\"])]\n",
    "    if len(schmelze) != 1:\n",
    "        continue\n",
    "    merged.append(pd.concat([row.to_frame().transpose().reset_index(drop=True), schmelze.reset_index(drop=True)], axis=1))\n",
    "\n",
    "df_merged_str1 = pd.concat(merged)\n",
    "df_merged_str1 = df_merged_str1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine df_schmelzen and Laenge Schmelze nothing added to 'GiessEnde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for _, row in data['Str1GiessLaengeSchmelzeInM'].iterrows():\n",
    "    schmelze = df_schmelzen[(df_schmelzen[\"GiessBeginn_DateTime\"] < row[\"DATE_TIME\"]) & (df_schmelzen[\"GiessEnde_DateTime\"] >= row[\"DATE_TIME\"])]\n",
    "    if len(schmelze) != 1:\n",
    "        continue\n",
    "    merged.append(pd.concat([row.to_frame().transpose().reset_index(drop=True), schmelze.reset_index(drop=True)], axis=1))\n",
    "\n",
    "df_str1_schmelzen = pd.concat(merged)\n",
    "df_str1_schmelzen = df_str1_schmelzen.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create interpolated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolated Sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_str1 = data['Str1GiessLaengeSequenzInM'].copy()\n",
    "\n",
    "df_seq_str1 = df_seq_str1[df_seq_str1['DATE_TIME'] >= '2019-05-15 11:30:00+00:00' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(start='2019-05-15 11:31:00+00:00', end='2019-08-30 23:59:00+00:00', freq='30s')\n",
    "df_times = pd.DataFrame({'DateTime': rng})\n",
    "df_times['ts'] = df_times.DateTime.values.astype(np.int64) // 10**9    #np arry by values, then 10**9 for ns\n",
    "\n",
    "time = df_seq_str1['TIME'].to_numpy() \n",
    "length = df_seq_str1['Str1GiessLaengeSequenzInM'].to_numpy()\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "interp_s = interp1d(time, length, kind='linear')\n",
    "\n",
    "new_time = df_times['ts'].to_numpy()\n",
    "\n",
    "inter_array = interp_s(new_time)\n",
    "\n",
    "str1_inter = pd.DataFrame({'DATE_TIME':new_time , 'Str1GiessLaengeSequenzInM': inter_array, 'TIME': new_time})\n",
    "str1_inter['DATE_TIME'] = pd.to_datetime(str1_inter['DATE_TIME'],unit='s').dt.tz_localize(\"UTC\")\n",
    "str1_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine df_schmelzen and str1_inter with 90min added to 'GiessEnde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for _, row in str1_inter.iterrows():\n",
    "    schmelze = df_schmelzen[(df_schmelzen[\"GiessBeginn_DateTime\"] < row[\"DATE_TIME\"]) & (df_schmelzen[\"Ende_DateTime\"] >= row[\"DATE_TIME\"])]\n",
    "    if len(schmelze) != 1:\n",
    "        continue\n",
    "    merged.append(pd.concat([row.to_frame().transpose().reset_index(drop=True), schmelze.reset_index(drop=True)], axis=1))\n",
    "\n",
    "str1_inter_extended = pd.concat(merged)\n",
    "str1_inter_extended = str1_inter_extended.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine df_schmelzen and str1_inter (nothing added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for _, row in str1_inter.iterrows():\n",
    "    schmelze = df_schmelzen[(df_schmelzen[\"GiessBeginn_DateTime\"] < row[\"DATE_TIME\"]) & (df_schmelzen[\"GiessEnde_DateTime\"] >= row[\"DATE_TIME\"])]\n",
    "    if len(schmelze) != 1:\n",
    "        continue\n",
    "    merged.append(pd.concat([row.to_frame().transpose().reset_index(drop=True), schmelze.reset_index(drop=True)], axis=1))\n",
    "\n",
    "df_str1_inter = pd.concat(merged)\n",
    "df_str1_inter = df_str1_inter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliar detection: Get Outliars with Schmelzen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_schmelzen_grouped = str1_schmelzen.groupby(str1_schmelzen['ChargenNr'])\n",
    "df_schmelzen_max = str1_schmelzen_grouped['Str1GiessLaengeSchmelzeInM'].max().to_frame()\n",
    "df_schmelzen_max = df_schmelzen_max.rename(columns={'Str1GiessLaengeSchmelzeInM': 'Str1GiessLaengeSchmelzeInM_max'})\n",
    "df_schmelzen_max = df_schmelzen_max.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schmelzen_max.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot('ChargenNr', 'Str1GiessLaengeSchmelzeInM_max', data = df_schmelzen_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schmelzen_max.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schmelzen_drop = df_schmelzen_max[df_schmelzen_max['Str1GiessLaengeSchmelzeInM_max']<10]\n",
    "schmelzen_drop = schmelzen_drop['ChargenNr'].to_numpy()\n",
    "schmelzen_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# str1_schmelzen[str1_schmelzen['ChargenNr']==473127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify the sequences of schmelzen_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schmelzen = pd.read_pickle(\"../final_data/df_schmelzen.pkl\")\n",
    "\n",
    "schmelzen = schmelzen.set_index('ChargenNr',drop=True)\n",
    "\n",
    "seq_drop = schmelzen.loc[schmelzen_drop]\n",
    "\n",
    "seq_drop = seq_drop['ChargenNrErsteSchmInSeq']\n",
    "seq_drop = seq_drop.drop_duplicates(keep='first')\n",
    "seq_drop = seq_drop.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at min charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_schmelzen_grouped = str1_schmelzen.groupby(str1_schmelzen['ChargenNr'])\n",
    "df_schmelzen_min = str1_schmelzen_grouped['Str1GiessLaengeSchmelzeInM'].min().to_frame()\n",
    "df_schmelzen_min = df_schmelzen_min.rename(columns={'Str1GiessLaengeSchmelzeInM': 'Str1GiessLaengeSchmelzeInM_min'})\n",
    "df_schmelzen_min = df_schmelzen_min.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot('ChargenNr', 'Str1GiessLaengeSchmelzeInM_min', data = df_schmelzen_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Sequences - create df_strang_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interv = df_interv.set_index(df_interv['ChargenNrErsteSchmInSeq'],drop=True)\n",
    "df_interv = df_interv.drop(seq_drop, axis=0)\n",
    "df_interv = df_interv.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create df_chargen_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate min and max for each charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_interv_grouped = df_interv.groupby(df_interv['ChargenNr'])\n",
    "\n",
    "df_interv_grouped_max = df_interv_grouped['Str1GiessLaengeSequenzInM'].max().to_frame()\n",
    "df_interv_grouped_min = df_interv_grouped['Str1GiessLaengeSequenzInM'].min().to_frame()\n",
    "\n",
    "df_interv_grouped_max = df_interv_grouped_max.rename(columns={'Str1GiessLaengeSequenzInM': 'Str1GiessLaengeSequenzInM_max'})\n",
    "\n",
    "df_interv_grouped_min = df_interv_grouped_min.rename(columns={'Str1GiessLaengeSequenzInM': 'Str1GiessLaengeSequenzInM_min'})\n",
    "\n",
    "chargen_nr = pd.merge(df_interv_grouped_min,df_interv_grouped_max,on=['ChargenNr'],\n",
    "                                            how='outer')\n",
    "\n",
    "chargen_nr = chargen_nr.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set min = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_value_to_zero (row):\n",
    "    if row['Str1GiessLaengeSequenzInM_min'] < 1:\n",
    "        row['Str1GiessLaengeSequenzInM_min'] = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "chargen_zero = chargen_nr.apply(set_value_to_zero, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge df_schmelzen and chargen_zero to get seq_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_chargen = pd.merge(chargen_zero,df_schmelzen[['ChargenNr','ChargenNrErsteSchmInSeq']],on=['ChargenNr'],\n",
    "                                            how='inner')\n",
    "df_chargen = pd.merge(df_chargen,df_schmelzen[['ChargenNr','GiessBeginn_DateTime']],on=['ChargenNr'],\n",
    "                                            how='inner')  #to sort the values, sometimes the chargen_nr is not ascending order\n",
    "\n",
    "df_chargen =df_chargen.set_index('GiessBeginn_DateTime', drop=False).sort_index()\n",
    "\n",
    "df_chargen = df_chargen.reset_index(drop=True)\n",
    "df_chargen = df_chargen.drop('GiessBeginn_DateTime', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chargen_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chargen_old = df_chargen.copy()\n",
    "\n",
    "#### set 'Str1GiessLaengeSequenzInM_min' of i equal to 'Str1GiessLaengeSequenzInM_max' of i-1\n",
    "\n",
    "df_chargen['Str1GiessLaengeSequenzInM_max_prev'] = df_chargen['Str1GiessLaengeSequenzInM_max'].shift(1)\n",
    "df_chargen['ChargenNrErsteSchmInSeq_prev'] = df_chargen['ChargenNrErsteSchmInSeq'].shift(1)\n",
    "\n",
    "def set_min (row):\n",
    "    if row['ChargenNrErsteSchmInSeq_prev'] == row['ChargenNrErsteSchmInSeq']:\n",
    "        row['Str1GiessLaengeSequenzInM_min'] = row['Str1GiessLaengeSequenzInM_max_prev']\n",
    "    return row\n",
    "\n",
    "df_chargen_nr = df_chargen.apply(set_min, axis=1)\n",
    "df_chargen_nr = df_chargen_nr.drop(['Str1GiessLaengeSequenzInM_max_prev','ChargenNrErsteSchmInSeq_prev' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_chargen_nr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove time dependence by assigning the specific cooling zone in which each section is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charNr(time, seq_nr):\n",
    "        return df_schmelzen.loc[(((df_schmelzen['GiessBeginnSchmelze'] <= time) & (df_schmelzen['EndeSchmelze'] >= time)) & (df_schmelzen['ChargenNrErsteSchmInSeq'] == seq_nr)), ['ChargenNr']].to_numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schmelzen = pd.read_pickle(\"../final_data/schmelzen.pkl\")\n",
    "\n",
    "def get_charNr(time, seq_nr):\n",
    "    try:\n",
    "        return df_schmelzen.loc[(((df_schmelzen['GiessBeginnSchmelze'] <= time) & (df_schmelzen['EndeSchmelze'] >= time)) & (df_schmelzen['ChargenNrErsteSchmInSeq'] == seq_nr)), ['ChargenNr']].to_numpy()[0][0]\n",
    "    except IndexError:\n",
    "        return df_schmelzen.loc[(((df_schmelzen['GiessBeginnSchmelze'] <= np.round(time.item(),-1)) & (df_schmelzen['EndeSchmelze'] >=  np.round(time.item(),-1))) & (df_schmelzen['ChargenNrErsteSchmInSeq'] == seq_nr)), ['ChargenNr']].to_numpy()[0][0]\n",
    "\n",
    "def charNr(row):\n",
    "    time =row['z1_begin_time']\n",
    "    row['ChargenNr'] = get_charNr(time, row['SequenzNr'])\n",
    "    return row    \n",
    "\n",
    "df_chargen_nr = pd.read_pickle(\"../final_data/chargen_nr.pkl\")\n",
    "\n",
    "# Zonen Start und Ende\n",
    "zonen = {'z1':[0.62,2.17],'z2a':[2.17,3.52],'z2b':[3.52,5.44],'z3a':[5.44,7.18],'z3b':[7.18,9.1],'z4':[9.1,11.02],'z5':[11.02,14.42],'zpy':[15.42,15.42]}\n",
    "\n",
    "# seq_max = pd.read_pickle(\"/home/di40438/bachelorarbeit/data/merged_1_all.pkl\") #'sequenz_laenge' nur bis zum Giessende \n",
    "seq_drop = pd.read_pickle(\"../final_data/seq_drop.pkl\")\n",
    "\n",
    "seq_max = pd.read_pickle(\"../final_data/df_str1_inter.pkl\") #'sequenz_laenge' nur bis zum Giessende \n",
    "\n",
    "seq_max = seq_max.set_index(seq_max['ChargenNrErsteSchmInSeq'],drop=True)\n",
    "\n",
    "seq_max = seq_max.drop(seq_drop, axis=0)  #drop the chargen from the outliar detection (sequences were already dropped)\n",
    "\n",
    "seq_max = seq_max.reset_index(drop=True)\n",
    "\n",
    "str1_seq = pd.read_pickle(\"../final_data/df_strang_1.pkl\") #sequenz_laenge auch noch später als Giessende\n",
    "\n",
    "sequence_nr = pd.read_pickle(\"../final_data/df_strang_1.pkl\")\n",
    "sequence_nr = sequence_nr['ChargenNrErsteSchmInSeq']\n",
    "sequence_nr = sequence_nr.drop_duplicates(keep='first')\n",
    "sequence_nr = sequence_nr.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str1_data = {}\n",
    "for sequence in tqdm(sequence_nr):   # für alle Sequenzen\n",
    "    \n",
    "    seq_max_length = seq_max[seq_max['ChargenNrErsteSchmInSeq']==sequence]\n",
    "    seq_max_length = seq_max_length.reset_index(drop=True)\n",
    "\n",
    "    seq = str1_seq[str1_seq['ChargenNrErsteSchmInSeq']==sequence]\n",
    "    seq = seq.reset_index(drop=True)\n",
    "\n",
    "    gil = seq['Str1GiessLaengeSequenzInM']  # Länge der Strecke, die das Förderband zurückgelegt hat\n",
    "    max_gil = np.max(gil)   # maximale Länge der Strecke, die das Förderband zurückgelegt hat\n",
    "    max_meter = np.max(seq_max_length['Str1GiessLaengeSequenzInM']) # tatsächliche maximale Länge der Schmelze \n",
    "\n",
    "    arr = np.arange(0, max_gil, 0.01)\n",
    "    df_length = pd.DataFrame({'length': arr})\n",
    "\n",
    "    time = seq['TIME'].to_numpy() \n",
    "    length = seq['Str1GiessLaengeSequenzInM'].to_numpy()\n",
    "\n",
    "    from scipy.interpolate import interp1d\n",
    "    interp = interp1d(length, time, kind='linear')  #x-Achse: Sequenzlänge, y-Achse: Zeitpunkte\n",
    "\n",
    "    gilz = []\n",
    "    cnt  = 0\n",
    "    section_length = 0.33        #Länge der Abschnitte in Meter\n",
    "    for section in range(int(np.max((max_meter+section_length)/section_length))):  #für jeden 0.33m-Abschnitt der Sequenz  \n",
    "        gilz.append({})                                                            # (der ite Abschnitt)\n",
    "        for z in zonen:        #jede Zone --> Verfolgen jedes Abschnitten durch jede Zone\n",
    "            mnt = 0\n",
    "            mxt = 0\n",
    "\n",
    "            mnt = interp(zonen[z][0]+(section*section_length))   #die Länge des Stranges bei jedem Abschnitt\n",
    "            mxt = interp(zonen[z][1]+((section+1)*section_length))\n",
    "            dt  = mxt-mnt\n",
    "\n",
    "            gilz[-1][z] = [mnt,mxt,dt]\n",
    "\n",
    "    seq_df = pd.DataFrame()\n",
    "    for section in range(len(gilz)):\n",
    "        z_df = pd.DataFrame()\n",
    "        for z in zonen:\n",
    "            section_z_df = pd.DataFrame(gilz[section][z], index=[z+'_begin_time',z+'_end_time',z+'_delta_time']).transpose()\n",
    "            z_df = pd.concat([z_df, section_z_df], axis=1)\n",
    "\n",
    "        seq_df = pd.concat([seq_df,z_df], axis=0)\n",
    "\n",
    "        seq_df['SequenzNr'] = seq['ChargenNrErsteSchmInSeq']\n",
    "        seq_df = seq_df.apply(charNr, axis=1)\n",
    "        seq_df = seq_df.reindex(sorted(seq_df.columns), axis=1)\n",
    "        seq_df = seq_df.reset_index(drop=True)\n",
    "\n",
    "        str1_data[sequence] = seq_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df = pd.DataFrame()\n",
    "for seq_nr in list(str1_data.keys()):\n",
    "     str1_df = pd.concat([str1_df,str1_data[seq_nr]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df = pd.read_pickle(\"../final_data/str1_inter_df_0.33_2.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add water of each zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = {'TundishTemperaturInC',\n",
    " 'Str1TempMittelLsInC',\n",
    " 'Str1TempMittelFsInC',\n",
    " 'Str2TempMittelLsInC',\n",
    " 'Str2TempMittelFsInC','Str1GiessLaengeSchmelzeInM',\n",
    " 'Str2GiessLaengeSchmelzeInM','Str1GiessLaengeSequenzInM',\n",
    " 'Str2GiessLaengeSequenzInM','Str2AusfLaengeSchmelzeInM',\n",
    " 'Str1AusfLaengeSchmelzeInM',\n",
    " 'Str1GiessGeschwInMproMin',\n",
    " 'Str2GiessGeschwInMproMin','Str2WasserZ1FsInLproMin',\n",
    " 'Str2WasserZ1LsInLproMin',\n",
    " 'Str2WasserZ2bFsInLproMin',\n",
    " 'Str2WasserZ4FsInLproMin',\n",
    " 'Str2WasserZ4LsInLproMin',\n",
    " 'Str2WasserZ3bLsInLproMin',\n",
    " 'Str2WasserZ3bFsInLproMin',\n",
    " 'Str2WasserZ1DiefflenInLproMin',\n",
    " 'Str2WasserZ2bLsInLproMin',\n",
    " 'Str2WasserZ1DillingenInLproMin',\n",
    " 'Str2WasserZ2aFsInLproMin',\n",
    " 'Str2WasserZ2aLsInLproMin',\n",
    " 'Str2WasserZ5FsInLproMin',\n",
    " 'Str2WasserZ5LsInLproMin',\n",
    " 'Str2WasserZ3aFsInLproMin',\n",
    " 'Str2WasserZ3aLsInLproMin',\n",
    "'Str1WasserZ1DiefflenInLproMin',\n",
    " 'Str1WasserZ1DillingenInLproMin'} \n",
    "  \n",
    "water_keys_str1 = [ele for ele in discr if ele not in unwanted] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "water_keys_str1 = sorted(water_keys_str1)\n",
    "water_keys_str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpol_func = {}\n",
    "for key in water_keys_str1:\n",
    "    name = key.replace('Str1Wasser','').replace('InLproMin','').replace('Z','z')\n",
    "    minutes = data[key]['TIME'].to_numpy() / 60\n",
    "    value = data[key][key].to_numpy()\n",
    "    interpol_func[name] = interp1d(minutes,value, kind='linear')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def integrate(X,z,side):\n",
    "        Y = [interpol_func[z+side](x) for x in X]\n",
    "        return scipy.integrate.trapz(Y,X, dx=1)\n",
    "\n",
    "def trapz_integration(row):\n",
    "    begin_m = row[z + '_begin_time'] / 60\n",
    "    end_m = row[z + '_end_time'] / 60\n",
    "    try:\n",
    "        row['water_' + z + '_' + side + '_inL'] = integrate([begin_m, end_m],z,side)\n",
    "        return row\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_water = ['z1','z2a','z2b','z3a','z3b','z4','z5']\n",
    "sides = ['Fs','Ls']\n",
    "for side in tqdm(sides):\n",
    "    for z in zones_water:\n",
    "        str1_df = str1_df.apply(trapz_integration,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the mean of the temperatur at the pyrometer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean with Integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_keys = ['Str1TempMittelLsInC', 'Str1TempMittelFsInC']\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "interpol_function_temp = {}\n",
    "for key in temp_keys:\n",
    "    minutes = data[key]['TIME'].to_numpy() / 60\n",
    "    value = data[key][key].to_numpy()\n",
    "    interpol_function_temp[key] = interp1d(minutes,value, kind='linear')\n",
    "\n",
    "import scipy\n",
    "def integrate_mean(X,key):\n",
    "        Y = [interpol_function_temp[key](x) for x in X]\n",
    "        return scipy.integrate.trapz(Y,X, dx=1)\n",
    "\n",
    "def temp_mean(row):\n",
    "    begin_t = row['zpy_begin_time'] / 60\n",
    "    end_t= row['zpy_end_time'] / 60\n",
    "    try:\n",
    "        row[key + '_mean'] = (1 / (end_t - begin_t)) * integrate_mean([begin_t, end_t],key)\n",
    "        return row\n",
    "    except ValueError:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in tqdm(temp_keys):\n",
    "    str1_df = str1_df.apply(temp_mean,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge str1_df with df_schmelzen to get other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df = str1_df.rename(columns={'ChargenNr_begin': 'ChargenNr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df = pd.merge(str1_df,df_schmelzen,on='ChargenNr',how='inner')                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df['strang_nr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_and_str_nr(row):\n",
    "    row['seq_id'] = str(row['SequenzNr']) + '_str_' + str(row['strang_nr'])\n",
    "    return row\n",
    "\n",
    "str1_df = str1_df.apply(seq_and_str_nr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str1_df_v2 = str1_df.drop(['Str2Format','Str2SollGiessGeschwInMproMin'],axis=1).rename(\n",
    "    columns={'Str1Format': 'Format', 'Str1SollGiessGeschwInMproMin': 'SollGiessGeschwInMproMin' })\n",
    "\n",
    "str1_df_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1_df_v2.to_pickle(\"../final_data/df_str1_transformed.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
