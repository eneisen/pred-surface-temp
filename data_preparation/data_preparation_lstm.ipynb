{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "import seaborn as sns\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapreparation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc4 = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/cc4_data.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minutes a section need to pass through the caster when casting speed is at the lowest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/di40438/bachelorarbeit/final_data/cc4_data.pkl\") \n",
    "data = df_cc4.drop('seq_id', axis=1).apply(pd.to_numeric)\n",
    "combined_grouped = data.groupby(data['ChargenNrErsteSchmInSeq'])\n",
    "grouped = combined_grouped['GiessGeschwInMproMin'].mean().to_frame()\n",
    "length_cc4 = 15.42\n",
    "min_v = np.round(grouped.min(),2)\n",
    "seq_len = int(np.ceil(length_cc4 / min_v))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting = ['DATE_TIME','ChargenNr','GiessBeginn_DateTime',\n",
    "            'GiessEnde_DateTime','TempMittelLsInC','GiessLaengeSequenzInM',\n",
    "    'TempMittelFsInC','ChargenNrErsteSchmInSeq','GiessLaengeSchmelzeInM','AusfLaengeSchmelzeInM','seq_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = ['DATE_TIME','TIME', 'ChargenNr', 'GiessBeginnSchmelze','GiessBeginn_DateTime',\n",
    "            'GiessEndeSchmelze','GiessEnde_DateTime','EndeSchmelze','Ende_DateTime','NrSchmelzeInSequenz',\n",
    "            \n",
    "            'WasserZ1FsInLproMin','WasserZ1LsInLproMin', 'WasserZ2bFsInLproMin','WasserZ4FsInLproMin',\n",
    "            'WasserZ4LsInLproMin','WasserZ3bLsInLproMin','WasserZ3bFsInLproMin','WasserZ1DiefflenInLproMin',\n",
    "            'WasserZ2bLsInLproMin','WasserZ1DillingenInLproMin','WasserZ2aLsInLproMin','WasserZ2aFsInLproMin',\n",
    "            'WasserZ5FsInLproMin','WasserZ5LsInLproMin','WasserZ3aFsInLproMin','WasserZ3aLsInLproMin',\n",
    "            'GiessGeschwInMproMin',  \n",
    "            'GiessGeschwInMproMin_integr','strang_nr','TempMittelLsInC_old','TempMittelFsInC_old',\n",
    "            'WasserZ1DiefflenInLproMin_integr', 'WasserZ1DillingenInLproMin_integr',\n",
    "            'GiessLaengeSchmelzeInM_delta', 'Format',\n",
    "           ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc4_keys = df_cc4.columns.to_list()\n",
    "\n",
    "column_keys = [key for key in cc4_keys if key not in unwanted]\n",
    "\n",
    "numeric_keys = column_keys.copy()\n",
    "numeric_keys.remove('seq_id')\n",
    "\n",
    "label_keys = ['TempMittelLsInC',\n",
    " 'TempMittelFsInC']\n",
    "\n",
    "feature_keys = [key for key in numeric_keys if key not in label_keys]\n",
    "feature_keys.remove('ChargenNrErsteSchmInSeq')\n",
    "\n",
    "wanted_keys = label_keys + feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/di40438/bachelorarbeit/final_data/label_keys_ts.pkl', 'wb') as fp:\n",
    "#     pickle.dump(label_keys, fp)\n",
    "# with open('/home/di40438/bachelorarbeit/final_data/feature_keys_ts.pkl', 'wb') as fp:\n",
    "#     pickle.dump(feature_keys, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc4_data = df_cc4.drop(unwanted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc4_data[['TempMittelLsInC','TempMittelFsInC']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5),  sharex=True)\n",
    "fig.suptitle('Distributions of Temperature in Datasets')\n",
    "\n",
    "sns.histplot(ax=axes[0], data=cc4_data, x='TempMittelLsInC', bins=100)\n",
    "sns.histplot(ax=axes[1], data=cc4_data, x='TempMittelFsInC', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train-, validation- and test-set\n",
    "#### don't split inbetween a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = cc4_data.groupby('ChargenNrErsteSchmInSeq')\n",
    "seq_keys = list(sequences.groups.keys())\n",
    "seq_keys.remove(475229)  #remove hot sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_full_keys, test_keys = train_test_split(seq_keys, test_size=0.25,random_state=42)\n",
    "train_keys, valid_keys = train_test_split(train_full_keys, test_size=0.25, random_state=42)\n",
    "train_keys.append(475229)\n",
    "train_full_keys.append(475229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/di40438/bachelorarbeit/final_data/train_keys_ts.pkl', 'wb') as fp:\n",
    "#     pickle.dump(train_keys, fp)\n",
    "# with open('/home/di40438/bachelorarbeit/final_data/valid_keys_ts.pkl', 'wb') as fp:\n",
    "#     pickle.dump(valid_keys, fp)\n",
    "# with open('/home/di40438/bachelorarbeit/final_data/test_keys_ts.pkl', 'wb') as fp:\n",
    "#     pickle.dump(test_keys, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(key_set,data):\n",
    "    df = pd.DataFrame()\n",
    "    for key in key_set:\n",
    "        df2 = pd.DataFrame()\n",
    "        df2 = data[data['ChargenNrErsteSchmInSeq']==key]\n",
    "        df = pd.concat([df,df2],axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_set(train_keys, cc4_data)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "valid_data = create_set(valid_keys, cc4_data)\n",
    "valid_data = valid_data.reset_index(drop=True)\n",
    "\n",
    "test_data = create_set(test_keys, cc4_data)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate all sequences with temperatures greater than 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_temp = train_data[(train_data['ZielTempTreiberInC']>800)]\n",
    "seq_id = list(df_high_temp['seq_id'].drop_duplicates(keep='first'))\n",
    "              \n",
    "df_hot_seq = train_data.set_index('seq_id', drop=True).loc[seq_id].reset_index(drop=False)\n",
    "df_hot_seq['seq_id'] = df_hot_seq['seq_id'].astype(str) + '_1'  #rename seq_id of first set \n",
    "\n",
    "df_hot_seq2 = train_data.set_index('seq_id', drop=True).loc[seq_id].reset_index(drop=False)    #create second set of hot sequences\n",
    "df_hot_seq2['seq_id'] = df_hot_seq2['seq_id'].astype(str) + '_2' #rename seq_id of  second set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data,df_hot_seq],axis=0).reset_index(drop=True)    #add first set oh hot sequences\n",
    "train_data = pd.concat([train_data,df_hot_seq2],axis=0).reset_index(drop=True)\n",
    "\n",
    "#One dataset of all the known data\n",
    "all_train_data = pd.concat([train_data, valid_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(10,12),  sharex=True, sharey=True)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=13) \n",
    "matplotlib.rc('ytick', labelsize=13) \n",
    "\n",
    "sns.histplot(ax=axes[0,0], data=train_data, x='TempMittelLsInC',color=sns.color_palette()[0])\n",
    "sns.histplot(ax=axes[0,1], data=train_data, x='TempMittelFsInC',color=sns.color_palette()[0])\n",
    "sns.histplot(ax=axes[1,0] ,data=valid_data, x='TempMittelLsInC',color=sns.color_palette()[0])\n",
    "sns.histplot(ax=axes[1,1] ,data=valid_data, x='TempMittelFsInC',color=sns.color_palette()[0])\n",
    "sns.histplot(ax=axes[2,0], data=test_data, x='TempMittelLsInC',color=sns.color_palette()[0] )\n",
    "sns.histplot(ax=axes[2,1], data=test_data, x='TempMittelFsInC', color=sns.color_palette()[0])\n",
    "\n",
    "axes[0,0].set_title('Training Set', fontdict={'fontsize':13} )\n",
    "axes[0,0].set(xticks=[]) \n",
    "axes[0,0].set_xlabel('Temperature [°C]', fontsize=13)\n",
    "axes[0,0].set_ylabel('Count', fontsize=13)\n",
    "axes[0,0].yaxis.grid(True)\n",
    "axes[0,0].set(xticks=[]) \n",
    "\n",
    "axes[0,1].set_title('Training Set', fontdict={'fontsize':13} )\n",
    "axes[0,1].set(xticks=[]) \n",
    "axes[0,1].set_xlabel('Temperature [°C]', fontsize=13)\n",
    "axes[0,1].set_ylabel('Count', fontsize=13)\n",
    "axes[0,1].yaxis.grid(True)\n",
    "axes[0,1].set(xticks=[]) \n",
    "\n",
    "axes[1,0].set_title('Validation Set', fontdict={'fontsize':13} )\n",
    "axes[1,0].set(xticks=[]) \n",
    "axes[1,0].set_xlabel('Temperature [°C]', fontsize=13)\n",
    "axes[1,0].set_ylabel('Count', fontsize=13)\n",
    "axes[1,0].yaxis.grid(True)\n",
    "axes[1,0].set(xticks=[]) \n",
    "\n",
    "axes[1,1].set_title('Validation Set', fontdict={'fontsize':13} )\n",
    "axes[1,1].set(xticks=[]) \n",
    "axes[1,1].set_xlabel('Temperature [°C]', fontsize=13)\n",
    "axes[1,1].set_ylabel('Count', fontsize=13)\n",
    "axes[1,1].yaxis.grid(True)\n",
    "axes[1,1].set(xticks=[]) \n",
    "\n",
    "axes[2,0].set_title('Test Set', fontdict={'fontsize':13} )\n",
    "axes[2,0].set(xticks=[]) \n",
    "axes[2,0].set_xlabel('Temperature Loose Side [°C]', fontsize=13)\n",
    "axes[2,0].set_ylabel('Count', fontsize=13)\n",
    "axes[2,0].yaxis.grid(True)\n",
    "axes[2,0].set(xticks=[]) \n",
    "\n",
    "axes[2,1].set_title('Test Set', fontdict={'fontsize':13} )\n",
    "axes[2,1].set(xticks=[]) \n",
    "axes[2,1].set_xlabel('Temperature Fixed Side [°C]', fontsize=13)\n",
    "axes[2,1].set_ylabel('Count', fontsize=13)\n",
    "axes[2,1].yaxis.grid(True)\n",
    "axes[2,1].set(xticks=[]) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_pickle(\"/home/di40438/bachelorarbeit/final_data/train_unsc.pkl\")\n",
    "# valid_data.to_pickle(\"/home/di40438/bachelorarbeit/final_data/valid_unsc.pkl\")\n",
    "# test_data.to_pickle(\"/home/di40438/bachelorarbeit/final_data/test_unsc.pkl\")\n",
    "# all_train_data.to_pickle(\"/home/di40438/bachelorarbeit/final_data/all_train_unsc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save ids since they are needed later\n",
    "id_train = train_data['seq_id'].to_frame()\n",
    "id_valid = valid_data['seq_id'].to_frame()\n",
    "id_test = test_data['seq_id'].to_frame()\n",
    "id_all_train = all_train_data['seq_id'].to_frame()\n",
    "\n",
    "#train set and validation set\n",
    "scaler_x_train = MinMaxScaler(feature_range=(0,1))\n",
    "train_x = scaler_x_train.fit_transform(train_data[feature_keys])\n",
    "df_train_x_norm = pd.DataFrame(train_x, columns=feature_keys)\n",
    "valid_x = scaler_x_train.transform(valid_data[feature_keys])\n",
    "df_valid_x_norm = pd.DataFrame(valid_x, columns=feature_keys)\n",
    "\n",
    "scaler_y_train = MinMaxScaler(feature_range=(0,1))\n",
    "train_y = scaler_y_train.fit_transform(train_data[label_keys])\n",
    "df_train_y_norm = pd.DataFrame(train_y, columns=label_keys)\n",
    "valid_y = scaler_y_train.transform(valid_data[label_keys])\n",
    "df_valid_y_norm = pd.DataFrame(valid_y, columns=label_keys)\n",
    "\n",
    "#all the training data\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "all_x = scaler_x.fit_transform(all_train_data[feature_keys])\n",
    "df_all_x_norm = pd.DataFrame(all_x, columns=feature_keys)\n",
    "test_x = scaler_x.transform(test_data[feature_keys])\n",
    "df_test_x_norm = pd.DataFrame(test_x, columns=feature_keys)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))\n",
    "all_y = scaler_y.fit_transform(all_train_data[label_keys])\n",
    "df_all_y_norm = pd.DataFrame(all_y, columns=label_keys)\n",
    "test_y = scaler_y.transform(test_data[label_keys])\n",
    "df_test_y_norm = pd.DataFrame(test_y, columns=label_keys)\n",
    "\n",
    "#create one dataframe\n",
    "train_norm = pd.concat([df_train_y_norm, df_train_x_norm], axis=1)\n",
    "valid_norm = pd.concat([df_valid_y_norm, df_valid_x_norm], axis=1)\n",
    "test_norm = pd.concat([df_test_y_norm, df_test_x_norm], axis=1)\n",
    "all_train_norm = pd.concat([df_all_y_norm, df_all_x_norm], axis=1)\n",
    "\n",
    "#add the ids again\n",
    "train_norm = pd.concat([train_norm,id_train],axis=1)\n",
    "valid_norm = pd.concat([valid_norm,id_valid],axis=1)\n",
    "test_norm = pd.concat([test_norm,id_test],axis=1)\n",
    "all_train_norm = pd.concat([all_train_norm,id_all_train],axis=1)\n",
    "\n",
    "train_norm = train_norm.reset_index(drop=True)\n",
    "valid_norm = valid_norm.reset_index(drop=True)\n",
    "test_norm = test_norm.reset_index(drop=True)\n",
    "all_train_norm = all_train_norm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_filename = \"/home/di40438/bachelorarbeit/final_data/scaler_y.save\"\n",
    "# joblib.dump(scaler_y, scaler_filename)\n",
    "\n",
    "# scaler_filename = \"/home/di40438/bachelorarbeit/final_data/scaler_x.save\"\n",
    "# joblib.dump(scaler_x, scaler_filename)\n",
    "\n",
    "# scaler_filename = \"/home/di40438/bachelorarbeit/final_data/scaler_train_y.save\"\n",
    "# joblib.dump(scaler_y_train, scaler_filename)\n",
    "\n",
    "# scaler_filename = \"/home/di40438/bachelorarbeit/final_data/scaler_train_x.save\"\n",
    "# joblib.dump(scaler_x_train, scaler_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_norm.to_pickle(\"/home/di40438/bachelorarbeit/final_data/train_norm.pkl\")\n",
    "# valid_norm.to_pickle(\"/home/di40438/bachelorarbeit/final_data/valid_norm.pkl\")\n",
    "# test_norm.to_pickle(\"/home/di40438/bachelorarbeit/final_data/test_norm.pkl\")\n",
    "# all_train_norm.to_pickle(\"/home/di40438/bachelorarbeit/final_data/all_train_norm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bring data in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_format(data):\n",
    "    length_cc4 = 15.42\n",
    "    min_v = np.round(grouped.min(),2)\n",
    "    seq_len = int(np.ceil(length_cc4 / min_v))\n",
    "    features = []\n",
    "    labels = []\n",
    "    data_set = {}\n",
    "\n",
    "    for _, group in data.groupby('seq_id'):\n",
    "        for i in range(len(group)-(seq_len-1)):\n",
    "            features.append(group[feature_keys].iloc[i:i+seq_len].to_numpy())  \n",
    "            labels.append(group[label_keys].iloc[i+(seq_len-1)].to_numpy())\n",
    "\n",
    "    data_set['x'] = np.stack(features)\n",
    "    data_set['y'] = np.stack(labels)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = lstm_format(train_norm)\n",
    "train_x_norm = train_n['x'].copy()\n",
    "train_y_norm = train_n['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_n = lstm_format(valid_norm)\n",
    "valid_x_norm = valid_n['x'].copy()\n",
    "valid_y_norm = valid_n['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = lstm_format(test_norm)\n",
    "test_x_norm = test_n['x'].copy()\n",
    "test_y_norm = test_n['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_n = lstm_format(all_train_norm)\n",
    "all_train_x_norm = all_train_n['x'].copy()\n",
    "all_train_y_norm = all_train_n['y'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save('/home/di40438/bachelorarbeit/final_data/train_x_norm.npy', train_x)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/train_y_norm.npy', train_y)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/valid_x_norm.npy', valid_x)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/valid_y_norm.npy', valid_y)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/test_x_norm.npy', test_x)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/test_y_norm.npy', test_y)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/all_train_x_norm.npy', all_train_x)\n",
    "# save('/home/di40438/bachelorarbeit/final_data/all_train_y_norm.npy', all_train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
