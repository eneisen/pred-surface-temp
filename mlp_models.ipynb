{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import kerastuner as kt\n",
    "import pickle\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from numpy import load\n",
    "from numpy import save\n",
    "from tensorflow.keras import regularizers\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"../final_data/train_unsc_mlp.pkl\")\n",
    "valid_data = pd.read_pickle(\"../final_data/valid_unsc_mlp.pkl\")\n",
    "test_data = pd.read_pickle(\"../final_data/test_unsc_mlp.pkl\")\n",
    "all_train_data = pd.read_pickle(\"/../final_data/all_train_unsc_mlp.pkl\")\n",
    "\n",
    "train_x = load('../final_data/train_x_mlp.npy')\n",
    "train_y = load('../final_data/train_y_mlp.npy')\n",
    "valid_x = load('../final_data/valid_x_mlp.npy')\n",
    "valid_y = load('../final_data/valid_y_mlp.npy')\n",
    "test_x = load('../final_data/test_x_mlp.npy')\n",
    "test_y = load('../final_data/test_y_mlp.npy')\n",
    "all_train_x = load('../final_data/all_x_mlp.npy')\n",
    "all_train_y = load('../final_data/all_y_mlp.npy')\n",
    "\n",
    "with open ('../final_data/label_keys_mlp.pkl', 'rb') as fp:\n",
    "    label_keys = pickle.load(fp)\n",
    "with open ('../final_data/feature_keys_mlp.pkl', 'rb') as fp:\n",
    "    feature_keys = pickle.load(fp)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y = joblib.load(\"../final_data/scaler_y_mlp.save\") \n",
    "scaler_y_train = joblib.load(\"../final_data/scaler_y_train_mlp.save\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_10_times(model, epochs, batch_size):\n",
    "    runs = 10\n",
    "    test_score = list()\n",
    "    train_score = list()\n",
    "    for i in range(runs):\n",
    "\n",
    "        np.random.seed(42 + i)\n",
    "        tf.random.set_seed(42 + i)\n",
    "\n",
    "        history = model.fit(all_train_x, all_train_y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                       )\n",
    "\n",
    "        y_pred_test = model.predict(test_x)\n",
    "        y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "        y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "\n",
    "        y_pred_train = model.predict(all_train_x)\n",
    "        y_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "        y_pred_train_unsc = scaler_y.inverse_transform(y_pred_train)\n",
    "        \n",
    "        mse_test = np.sqrt(mean_squared_error(y_pred_test_unsc, y_test_unsc))  \n",
    "        test_score.append(mse_test)\n",
    "\n",
    "        mse_train = np.sqrt(mean_squared_error(y_pred_train_unsc, y_train_unsc))  \n",
    "        train_score.append(mse_train)\n",
    "\n",
    "    return  train_score, test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "def build_model_simple_mlp():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:]),\n",
    "        keras.layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(loss='mse',           \n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-3),           \n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp = build_model_simple_mlp()\n",
    "\n",
    "simple_mlp_history = simple_mlp.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp = keras.models.load_model(\"../final_data/models/simple_mlp_train\")\n",
    "hist_simple_mlp = pd.read_pickle(\"../final_data/hist_simple_mlp_train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_mlp).plot(figsize=(8, 5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate RMSE on training set\n",
    "y_pred_train = simple_mlp.predict(train_x)\n",
    "y_train_unsc = scaler_y_train.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_y_train.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE on validation set\n",
    "y_pred_val = simple_mlp.predict(valid_x)\n",
    "y_val_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_y_train.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_mlp = build_model_simple_mlp()\n",
    "\n",
    "simple_mlp_history = simple_mlp.fit(all_train_x, all_train_y,\n",
    "                    epochs=160,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp = keras.models.load_model(\"../final_data/models/simple_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate RMSE on all training data\n",
    "y_pred_all_train = simple_mlp.predict(all_train_x)\n",
    "y_all_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_all_train_unsc = scaler_y.inverse_transform(y_pred_all_train)\n",
    "np.sqrt(mean_squared_error(y_all_train_unsc, y_pred_all_train_unsc))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Caculate RMSE on test set\n",
    "y_pred_test = simple_mlp.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp = build_model_simple_mlp()\n",
    "epochs = 160\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(simple_mlp, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_simple_mlp = pd.read_pickle(\"../final_data/rmse_train_simple_mlp.pkl\")\n",
    "rmse_test_simple_mlp = pd.read_pickle(\"../final_data/rmse_test_simple_mlp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_simple_mlp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_simple_mlp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "def build_model_simple_dropout():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:]),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "                 \n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                  \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "model_simple_dropout = build_model_simple_dropout()\n",
    "\n",
    "history_simple_dropout = model_simple_dropout.fit(train_x, train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_dropout = pd.read_pickle(\"../final_data/hist_simple_mlp_drop.pkl\")\n",
    "model_simple_dropout = keras.models.load_model(\"../final_data/models/simple_mlp_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_dropout).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.004)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_simple_dropout.predict(train_x)\n",
    "y_train_unsc = scaler_y_train.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_y_train.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_simple_dropout.predict(valid_x)\n",
    "y_val_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_y_train.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model with Weight Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model_simple_weight_reg():\n",
    "    model_kernel = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal', input_shape=train_x.shape[1:],\n",
    "                          kernel_regularizer=regularizers.l2(0.001)),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_kernel.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                 \n",
    "                 )\n",
    "    return model_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "model_simple_weight_reg = build_model_simple_weight_reg()\n",
    "\n",
    "history_simple_weight_reg = model_simple_weight_reg.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_weight_reg = pd.read_pickle(\"../final_data/hist_simple_mlp_weight.pkl\")\n",
    "model_simple_weight_reg = keras.models.load_model(\"../final_data/models/simple_mlp_weight_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_simple_weight_reg).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.004)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_simple_weight_reg.predict(train_x)\n",
    "y_train_unsc = scaler_y_train.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_y_train.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model_simple_weight_reg.predict(valid_x)\n",
    "y_val_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_y_train.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Dropout Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tuner implementation of Hyperband\n",
    "Pickle containing all the models Hyperband testes can be loaded and therefore the best model found as well. So there is no need to run the Hyperparameter Search with Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load the pickle with the Hyperband search results, the following cell must be run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_mlp (hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    hp_units = hp.Int(\"unit\",min_value=32,max_value=160,step=32)\n",
    "    hp_dropout = hp.Choice(\"mlp_layer_dropout\",values = [ 0.2, 0.3])\n",
    "    hp_number_of_layers = hp.Int(\"layers\",min_value=0,max_value=2,step=1)\n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "                            units= hp_units, \n",
    "                            kernel_constraint=keras.constraints.max_norm(max_value=1),                    \n",
    "                            activation='relu',\n",
    "                            \n",
    "                            input_shape=train_x.shape[1:]     \n",
    "                     ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(hp_dropout))\n",
    "    \n",
    "  \n",
    "\n",
    "    for i in range(hp_number_of_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units = hp_units,\n",
    "                        kernel_constraint=keras.constraints.max_norm(max_value=1),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_normal'\n",
    "                        ))\n",
    "        model.add(keras.layers.Dropout(hp_dropout))\n",
    "        \n",
    "        \n",
    "\n",
    "    model.add(keras.layers.Dense(2, kernel_initializer='he_normal'))\n",
    "        \n",
    "    mlp_learning_rate = hp.Choice('learning_rate', values = [ 1e-3, 1e-4])\n",
    "    optimizer = keras.optimizers.Adam(lr=mlp_learning_rate)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.tuners.Hyperband):\n",
    "  def run_trial(self, trial, *args, **kwargs):\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\",values = [32, 128, 512])\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This must only be executed if Hyperband should search again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = MyTuner(model_builder_mlp,\n",
    "#                 objective='val_loss',\n",
    "#                 max_epochs = 100,\n",
    "#                 factor = 3,\n",
    "#                 seed = 42,\n",
    "#                 directory = \"k\",\n",
    "#                 project_name = 'k3')\n",
    "\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# tuner.search(train_x,\n",
    "#              train_y,\n",
    "#              epochs = 150,\n",
    "#              validation_data = (valid_x, valid_y),\n",
    "#              callbacks = [stop_early]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pickle of the Hyperband search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hyper_dropout = pickle.load(open(\"../final_data/models/mlp_drop_hyperband.pkl\",'rb'))\n",
    "\n",
    "print(tuner_hyper_dropout.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Either: Keras Tuner implementation of Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_dropout.get_best_hyperparameters(num_trials=1)[0]\n",
    "mlp_dropout_train = tuner_hyper_dropout.hypermodel.build(best_hps)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "# Retrain the model\n",
    "history_mlp_dropout_train = mlp_dropout_train.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: Rebuild best Hyperband model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "def build_model_dropout_tuned():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                           input_shape=train_x.shape[1:],\n",
    "                           kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                          kernel_constraint=keras.constraints.max_norm(max_value=1),),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),     \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "mlp_dropout_train = build_model_dropout_tuned()\n",
    "\n",
    "history_mlp_dropout_train = mlp_dropout.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained Hyperband model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dropout_train = pd.read_pickle(\"../final_data/hist_mlp_dropout_hyper_train.pkl\")\n",
    "mlp_dropout_train = keras.models.load_model(\"../final_data/models/mlp_dropout_hyper_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_dropout).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = mlp_dropout.predict(train_x)\n",
    "y_train_unsc = scaler_y_train.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_y_train.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = mlp_dropout.predict(valid_x)\n",
    "y_val_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_y_train.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Either: rebuild Keras Tuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_dropout.get_best_hyperparameters(num_trials=1)[0]\n",
    "mlp_dropout_test = tuner_hyper_dropout.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history_mlp_dropout_test = mlp_dropout_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=171,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: rebuild best model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dropout_test = build_model_dropout_tuned()\n",
    "\n",
    "history_mlp_dropout_test = mlp_dropout_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=171,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dropout_test = keras.models.load_model(\"../final_data/models/mlp_dropout_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_train = mlp_dropout_test.predict(all_train_x)\n",
    "y_all_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_all_train_unsc = scaler_y.inverse_transform(y_pred_all_train)\n",
    "np.sqrt(mean_squared_error(y_all_train_unsc, y_pred_all_train_unsc))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = mlp_dropout_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMSimple_model = build_model_dropout_tuned()\n",
    "epochs = 171\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(LSTMSimple_model, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_dropout_tuned = pd.read_pickle(\"../final_data/rmse_train_mlp_dropout_tuned.pkl\")\n",
    "rmse_test_mlp_dropout_tuned = pd.read_pickle(\"../final_data/rmse_test_mlp_dropout_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_dropout_tuned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_mlp_dropout_tuned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Weight Regularization Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tuner implementation of Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_mlp (hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    hp_kernel_reg = hp.Choice(\"mlp_layer_kernel_reg\",values = [1e-4, 1e-3])\n",
    "    hp_units = hp.Int(\"unit\",min_value=32,max_value=160,step=32)\n",
    "    hp_number_of_layers = hp.Int(\"layers\",min_value=0,max_value=2,step=1)\n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "                            units= hp_units, \n",
    "                            kernel_regularizer=regularizers.l2(hp_kernel_reg),                  \n",
    "                            activation='relu',\n",
    "                            input_shape=train_x.shape[1:]     \n",
    "                     ))\n",
    "    \n",
    "    for i in range(hp_number_of_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units = hp_units,\n",
    "                        kernel_regularizer=regularizers.l2(hp_kernel_reg),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_normal'\n",
    "                        ))\n",
    "        \n",
    "\n",
    "    model.add(keras.layers.Dense(2, kernel_initializer='he_normal'))\n",
    "        \n",
    "    mlp_learning_rate = hp.Choice('learning_rate', values = [ 1e-3, 1e-4])\n",
    "    optimizer = keras.optimizers.Adam(lr=mlp_learning_rate)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "class MyTuner(kt.tuners.Hyperband):\n",
    "  def run_trial(self, trial, *args, **kwargs):\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\",values = [32, 128, 512])\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_mlp (hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    hp_kernel_reg = hp.Choice(\"mlp_layer_kernel_reg\",values = [1e-3, 1e-4])\n",
    "    hp_units = hp.Choice(\"unit\",values = [16, 32, 64, 128, 192 ]) \n",
    "    hp_number_of_layers = hp.Choice(\"layers\",values = [0,1,2,3]) \n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "                            units= hp_units, \n",
    "                            kernel_regularizer=regularizers.l2(hp_kernel_reg),          \n",
    "                            activation='relu',\n",
    "                            input_shape=train_x.shape[1:]     \n",
    "                     ))\n",
    "\n",
    "    for i in range(hp_number_of_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units = hp_units,\n",
    "                        kernel_regularizer=regularizers.l2(hp_kernel_reg),\n",
    "                        activation='relu',\n",
    "                        kernel_initializer='he_normal'\n",
    "                        ))\n",
    "\n",
    "    model.add(keras.layers.Dense(2, kernel_initializer='he_normal'))\n",
    "        \n",
    "    mlp_learning_rate = hp.Choice('learning_rate', values = [ 1e-3, 1e-4])\n",
    "    optimizer = keras.optimizers.Adam(lr=mlp_learning_rate)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "              \n",
    "              \n",
    "class MyTuner(kt.tuners.Hyperband):\n",
    "  def run_trial(self, trial, *args, **kwargs):\n",
    "    kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\",values = [32, 128, 512])\n",
    "    super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = MyTuner(model_builder_mlp,\n",
    "                objective='val_loss',\n",
    "                max_epochs = 100,\n",
    "                factor = 3,\n",
    "                seed = 42,\n",
    "                directory = \"/home/di40438/bachelorarbeit/data/keras_tuner\",\n",
    "                project_name = 'mlp_weight_reg_1')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "tuner.search(train_x,\n",
    "             train_y,\n",
    "             epochs = 150,\n",
    "             validation_data = (valid_x, valid_y),\n",
    "             callbacks = [stop_early]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Tuner implementation of Hyperband\n",
    "Hyperparameter search may take a while even with limited data, resulting architectur when used with all data is provided next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hyper_weight = pickle.load(open(\"../final_data/models/tuner_hyper_weight.pkl\",'rb'))\n",
    "\n",
    "print(tuner_hyper_weight.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_weight.get_best_hyperparameters(num_trials=1)[0]\n",
    "hypermodel_weight_reg = tuner_hyper_weight.hypermodel.build(best_hps)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "# Retrain the model\n",
    "history_hypermodel_weight_reg = hypermodel_weight_reg.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: Rebuild best Hyperband model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_weight_reg_tuned():\n",
    "    model_reg = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                           input_shape=train_x.shape[1:],\n",
    "                            kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dense(2, kernel_initializer='he_normal')\n",
    "    ])\n",
    "    model_reg.compile(loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),     \n",
    "                 )\n",
    "    return model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "mlp_weight_reg_train = build_model_weight_reg_tuned()\n",
    "\n",
    "history_mlp_weight_reg_train = mlp_weight_reg_train.fit(train_x, train_y,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weight_reg_train = pd.read_pickle(\"../final_data/hist_hypermodel_mlp_weight_reg.pkl\")\n",
    "mlp_weight_reg_train = keras.models.load_model(\"../final_data/models/hypermodel_mlp_weight_reg_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_weight_reg_train).plot(figsize=(8, 5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = mlp_weight_reg_train.predict(train_x)\n",
    "y_train_unsc = scaler_y_train.inverse_transform(train_y)\n",
    "y_pred_train_unsc = scaler_y_train.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = mlp_weight_reg_train.predict(valid_x)\n",
    "y_val_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_val_unsc = scaler_y_train.inverse_transform(y_pred_val)\n",
    "np.sqrt(mean_squared_error(y_val_unsc, y_pred_val_unsc))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Either: rebuild Keras Tuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_hyper_weight.get_best_hyperparameters(num_trials=1)[0]\n",
    "mlp_weight_reg_test = tuner_hyper_weight.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history_mlp_weight_reg_test = mlp_weight_reg_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=167,\n",
    "                    batch_size=32,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or: rebuild best model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_weight_reg_test = build_model_weight_reg_tuned()\n",
    "\n",
    "history_mlp_weight_reg_test = mlp_weight_reg_test.fit(all_train_x, all_train_y,\n",
    "                    epochs=167,\n",
    "                    batch_size=32,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_weight_reg_test = keras.models.load_model(\"../final_data/models/mlp_weight_reg_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_train = mlp_weight_reg_test.predict(all_train_x)\n",
    "y_all_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_all_train_unsc = scaler_y.inverse_transform(y_pred_all_train)\n",
    "np.sqrt(mean_squared_error(y_all_train_unsc, y_pred_all_train_unsc))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = mlp_weight_reg_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc = scaler_y.inverse_transform(y_pred_test)\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_weight_reg = build_model_weight_reg_tuned()\n",
    "epochs = 167\n",
    "batch_size = 32\n",
    "train_score, test_score = test_10_times(mlp_weight_reg, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_weight_reg = pd.read_pickle(\"../final_data/rmse_train_mlp_weight_reg.pkl\")\n",
    "rmse_test_mlp_weight_reg = pd.read_pickle(\"../final_data/rmse_test_mlp_weight_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_mlp_weight_reg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_test_mlp_weight_reg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Simple MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not all models were run: Read saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_simple_mlp = pd.read_pickle(\"../final_data/hist_simple_mlp_train.pkl\")\n",
    "hist_simple_dropout = pd.read_pickle(\"../final_data/hist_simple_mlp_drop.pkl\")\n",
    "hist_simple_weight_reg = pd.read_pickle(\"../final_data/hist_simple_mlp_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_simple_mlps, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(hist_simple_mlp['loss'], label='SimpleMLP_Loss', color='dimgrey' )\n",
    "ax.plot(hist_simple_mlp['val_loss'], label='SimpleMLP_Validation_Loss', color='black' )\n",
    "ax.plot(hist_simple_dropout['loss'], label='SimpleDropout_Loss', color='indianred')\n",
    "ax.plot(hist_simple_dropout['val_loss'], label='SimpleDropout_Validation_Loss', color='red')\n",
    "ax.plot(hist_simple_weight_reg['loss'], label='SimpleWeightReg_Loss', color='c')\n",
    "ax.plot(hist_simple_weight_reg['val_loss'], label='SimpleWeightReg_Validation_Loss', color='blue')\n",
    "ax.set_ylim(0.001, 0.004)\n",
    "ax.set(xlabel=' Epochs', ylabel='Score')\n",
    "ax.set_xlabel('Epochs', fontsize=15)\n",
    "ax.set_ylabel('Score', fontsize=15)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "ax.legend(loc='upper center',prop={'size': 12} )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not all models were run: Read saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dropout_train = pd.read_pickle(\"../final_data/hist_mlp_dropout_hyper_train.pkl\")\n",
    "hist_weight_reg_train = pd.read_pickle(\"../final_data/hist_hypermodel_mlp_weight_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_final_mlps, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(hist_dropout_train['loss'][:300], label='MLPDropout_Loss', color='indianred' )\n",
    "ax.plot(hist_dropout_train['val_loss'][:300], label='MLPDropout_Validation_Loss', color='red' )\n",
    "ax.plot(hist_weight_reg_train['loss'][:300], label='MLPWeightDecay_Loss', color='c')\n",
    "ax.plot(hist_weight_reg_train['val_loss'][:300], label='MLPWeightDecay_Validation_Loss', color='blue')\n",
    "ax.set_ylim(0.001, 0.004)\n",
    "ax.set(xlabel=' Epochs', ylabel='Score')\n",
    "ax.set_xlabel('Epochs', fontsize=15)\n",
    "ax.set_ylabel('Score', fontsize=15)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "ax.legend(loc='upper left',prop={'size': 13} )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load best model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_weight_reg_train = keras.models.load_model(\"../final_data/models/hypermodel_mlp_weight_reg_train\")\n",
    "mlp_weight_reg_test = keras.models.load_model(\"../final_data/models/mlp_weight_reg_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = mlp_weight_reg_test.predict(all_train_x)\n",
    "y_train_unsc = scaler_y.inverse_transform(all_train_y)\n",
    "y_pred_train_unsc = scaler_y.inverse_transform(y_pred_train)\n",
    "np.sqrt(mean_squared_error(y_train_unsc, y_pred_train_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid = mlp_weight_reg_train.predict(valid_x)\n",
    "y_valid_unsc = scaler_y_train.inverse_transform(valid_y)\n",
    "y_pred_valid_unsc = scaler_y_train.inverse_transform(y_pred_valid)\n",
    "np.sqrt(mean_squared_error(y_valid_unsc, y_pred_valid_unsc))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_final = mlp_weight_reg_test.predict(test_x)\n",
    "y_test_unsc = scaler_y.inverse_transform(test_y)\n",
    "y_pred_test_unsc_final = scaler_y.inverse_transform(y_pred_test_final)\n",
    "np.sqrt(mean_squared_error(y_test_unsc, y_pred_test_unsc_final))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_train_unsc, y_train_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.set(xticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_valid_unsc, y_valid_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.set(xticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,  figsize=(5, 5),  sharex=True, sharey=True)\n",
    "plt.xlim(550, 900)\n",
    "plt.ylim(550, 900)\n",
    "\n",
    "ax1.scatter( y_pred_test_unsc_final, y_test_unsc,  c= 'dodgerblue',s=1)\n",
    "ax1.plot([550,900],[550,900], c='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Predicted Temperatures [°C] ', fontsize=15)\n",
    "ax1.set_ylabel('Measured Temperature [°C]',fontsize=15)\n",
    "ax1.set(yticks=[]) \n",
    "ax1.xaxis.grid(True)\n",
    "ax1.set(xticks=[]) \n",
    "ax1.yaxis.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
